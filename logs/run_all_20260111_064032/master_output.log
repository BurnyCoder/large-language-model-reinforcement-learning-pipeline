
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Run All â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                      â”‚
â”‚  LLM RL Training Pipelines                                                                                           â”‚
â”‚                                                                                                                      â”‚
â”‚  Mode: ALL                                                                                                           â”‚
â”‚  Scripts: smollm2_135m.py, qwen2.5_0.5b.py                                                                           â”‚
â”‚                                                                                                                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

                                 System Information                                 
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Property          â”ƒ Value                                                        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Platform          â”‚ Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.39 â”‚
â”‚ Python            â”‚ 3.12.3                                                       â”‚
â”‚ Working Directory â”‚ /home/burny/projects/ml-playground/llmrl                     â”‚
â”‚ Timestamp         â”‚ 2026-01-11 06:40:32                                          â”‚
â”‚ GPU 0             â”‚ NVIDIA GeForce RTX 5070 Laptop GPU (8.0 GB)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Running smollm2_135m.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Command: python /home/burny/projects/ml-playground/llmrl/smollm2_135m.py
Working directory: /home/burny/projects/ml-playground/llmrl


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                       
â”‚
â”‚  Training Pipeline                                                                                                    
â”‚
â”‚  Run ID: 20260111_064045_89cu | Running 4 algorithm(s): sft, reward, dpo, grpo                                        
â”‚
â”‚                                                                                                                       
â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ System Information 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

                                 System Information
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Component         â”ƒ Details                                                      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Platform          â”‚ Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.39 â”‚
â”‚ Python            â”‚ 3.12.3                                                       â”‚
â”‚ Working Directory â”‚ /home/burny/projects/ml-playground/llmrl                     â”‚
â”‚ Timestamp         â”‚ 2026-01-11 06:40:45                                          â”‚
â”‚ GPU 0             â”‚ NVIDIA GeForce RTX 5070 Laptop GPU (8.0 GB)                  â”‚
â”‚ CUDA Version      â”‚ 12.8                                                         â”‚
â”‚ RAM               â”‚ 15.3 GB (66.6% used)                                         â”‚
â”‚ Disk              â”‚ 1006.9 GB (7.4% used)                                        â”‚
â”‚ CPU Cores         â”‚ 16                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Pipeline Configuration 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SFT
                                SFT Config
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                   â”ƒ Value                                    â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ model_name                  â”‚ HuggingFaceTB/SmolLM2-135M-Instruct      â”‚
â”‚ output_dir                  â”‚ runs/20260111_064045_89cu/test-model-sft â”‚
â”‚ dataset_name                â”‚ trl-lib/Capybara                         â”‚
â”‚ dataset_split               â”‚ train                                    â”‚
â”‚ max_samples                 â”‚ 10                                       â”‚
â”‚ per_device_train_batch_size â”‚ 1                                        â”‚
â”‚ gradient_accumulation_steps â”‚ 1                                        â”‚
â”‚ max_steps                   â”‚ 10                                       â”‚
â”‚ gradient_checkpointing      â”‚ No                                       â”‚
â”‚ bf16                        â”‚ No                                       â”‚
â”‚ use_liger_kernel            â”‚ No                                       â”‚
â”‚ dataloader_pin_memory       â”‚ No                                       â”‚
â”‚ dataloader_num_workers      â”‚ 0                                        â”‚
â”‚ logging_steps               â”‚ 1                                        â”‚
â”‚ logging_strategy            â”‚ steps                                    â”‚
â”‚ log_level                   â”‚ info                                     â”‚
â”‚ report_to                   â”‚ wandb                                    â”‚
â”‚ save_steps                  â”‚ 5                                        â”‚
â”‚ save_strategy               â”‚ steps                                    â”‚
â”‚ save_total_limit            â”‚ 2                                        â”‚
â”‚ clean_output_dir            â”‚ Yes                                      â”‚
â”‚ verbose                     â”‚ Yes                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

REWARD
                                REWARD Config
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                   â”ƒ Value                                       â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ model_name                  â”‚ HuggingFaceTB/SmolLM2-135M-Instruct         â”‚
â”‚ output_dir                  â”‚ runs/20260111_064045_89cu/test-model-reward â”‚
â”‚ dataset_name                â”‚ trl-lib/ultrafeedback_binarized             â”‚
â”‚ dataset_split               â”‚ train                                       â”‚
â”‚ max_samples                 â”‚ 10                                          â”‚
â”‚ per_device_train_batch_size â”‚ 1                                           â”‚
â”‚ gradient_accumulation_steps â”‚ 1                                           â”‚
â”‚ max_steps                   â”‚ 10                                          â”‚
â”‚ gradient_checkpointing      â”‚ No                                          â”‚
â”‚ bf16                        â”‚ No                                          â”‚
â”‚ use_liger_kernel            â”‚ No                                          â”‚
â”‚ dataloader_pin_memory       â”‚ No                                          â”‚
â”‚ dataloader_num_workers      â”‚ 0                                           â”‚
â”‚ logging_steps               â”‚ 1                                           â”‚
â”‚ logging_strategy            â”‚ steps                                       â”‚
â”‚ log_level                   â”‚ info                                        â”‚
â”‚ report_to                   â”‚ wandb                                       â”‚
â”‚ save_steps                  â”‚ 5                                           â”‚
â”‚ save_strategy               â”‚ steps                                       â”‚
â”‚ save_total_limit            â”‚ 2                                           â”‚
â”‚ clean_output_dir            â”‚ Yes                                         â”‚
â”‚ verbose                     â”‚ Yes                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DPO
                                DPO Config
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                   â”ƒ Value                                    â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ model_name                  â”‚ HuggingFaceTB/SmolLM2-135M-Instruct      â”‚
â”‚ output_dir                  â”‚ runs/20260111_064045_89cu/test-model-dpo â”‚
â”‚ dataset_name                â”‚ trl-lib/ultrafeedback_binarized          â”‚
â”‚ dataset_split               â”‚ train                                    â”‚
â”‚ max_samples                 â”‚ 10                                       â”‚
â”‚ per_device_train_batch_size â”‚ 1                                        â”‚
â”‚ gradient_accumulation_steps â”‚ 1                                        â”‚
â”‚ max_steps                   â”‚ 10                                       â”‚
â”‚ gradient_checkpointing      â”‚ No                                       â”‚
â”‚ bf16                        â”‚ No                                       â”‚
â”‚ use_liger_kernel            â”‚ No                                       â”‚
â”‚ dataloader_pin_memory       â”‚ No                                       â”‚
â”‚ dataloader_num_workers      â”‚ 0                                        â”‚
â”‚ logging_steps               â”‚ 1                                        â”‚
â”‚ logging_strategy            â”‚ steps                                    â”‚
â”‚ log_level                   â”‚ info                                     â”‚
â”‚ report_to                   â”‚ wandb                                    â”‚
â”‚ save_steps                  â”‚ 5                                        â”‚
â”‚ save_strategy               â”‚ steps                                    â”‚
â”‚ save_total_limit            â”‚ 2                                        â”‚
â”‚ clean_output_dir            â”‚ Yes                                      â”‚
â”‚ verbose                     â”‚ Yes                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

GRPO
                                GRPO Config
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                   â”ƒ Value                                     â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ model_name                  â”‚ HuggingFaceTB/SmolLM2-135M-Instruct       â”‚
â”‚ output_dir                  â”‚ runs/20260111_064045_89cu/test-model-grpo â”‚
â”‚ dataset_name                â”‚ trl-lib/DeepMath-103K                     â”‚
â”‚ dataset_split               â”‚ train                                     â”‚
â”‚ max_samples                 â”‚ 10                                        â”‚
â”‚ per_device_train_batch_size â”‚ 1                                         â”‚
â”‚ gradient_accumulation_steps â”‚ 1                                         â”‚
â”‚ max_steps                   â”‚ 10                                        â”‚
â”‚ gradient_checkpointing      â”‚ No                                        â”‚
â”‚ bf16                        â”‚ No                                        â”‚
â”‚ use_liger_kernel            â”‚ No                                        â”‚
â”‚ dataloader_pin_memory       â”‚ No                                        â”‚
â”‚ dataloader_num_workers      â”‚ 0                                         â”‚
â”‚ logging_steps               â”‚ 1                                         â”‚
â”‚ logging_strategy            â”‚ steps                                     â”‚
â”‚ log_level                   â”‚ info                                      â”‚
â”‚ report_to                   â”‚ wandb                                     â”‚
â”‚ save_steps                  â”‚ 5                                         â”‚
â”‚ save_strategy               â”‚ steps                                     â”‚
â”‚ save_total_limit            â”‚ 2                                         â”‚
â”‚ clean_output_dir            â”‚ Yes                                       â”‚
â”‚ verbose                     â”‚ Yes                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        GRPO Extra Config
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ Parameter             â”ƒ Value â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ reward_func           â”‚ None  â”‚
â”‚ num_generations       â”‚ 2     â”‚
â”‚ max_completion_length â”‚ 32    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Training Progress 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€



â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SFT Training 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â„¹ Model: HuggingFaceTB/SmolLM2-135M-Instruct
â„¹ Dataset: trl-lib/Capybara
â„¹ Output: runs/20260111_064045_89cu/test-model-sft
â„¹ Output directory ready: runs/20260111_064045_89cu/test-model-sft
[06:40:45] INFO     Starting SFT training with model=HuggingFaceTB/SmolLM2-135M-Instruct                                
sft.py:40
Loading dataset: trl-lib/Capybara (split: train)

â„¹ Limited dataset from 15,806 to 10 samples
             Dataset Information
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Property    â”ƒ Value                       â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Dataset     â”‚ trl-lib/Capybara            â”‚
â”‚ Samples     â”‚ 10                          â”‚
â”‚ Columns     â”‚ source, messages, num_turns â”‚
â”‚ Sample Keys â”‚ source, messages, num_turns â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â„¹ Creating SFT trainer...
The model is already on multiple devices. Skipping the move to device specified in `args`.
max_steps is given, it will override any value given in num_train_epochs
Starting SFT training loop...
The following columns in the Training set don't have a corresponding argument in `LlamaForCausalLM.forward` and have 
been ignored: messages, num_turns, source. If messages, num_turns, source are not expected by 
`LlamaForCausalLM.forward`,  you can safely ignore this message.
***** Running training *****
  Num examples = 10
  Num Epochs = 1
  Instantaneous batch size per device = 1
  Total train batch size (w. parallel, distributed & accumulation) = 1
  Gradient Accumulation steps = 1
  Total optimization steps = 10
  Number of trainable parameters = 134,515,008
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: burny (burny-burny) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run zap0zm1t
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/burny/projects/ml-playground/llmrl/wandb/run-20260111_064052-zap0zm1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-mountain-3
wandb: â­ï¸ View project at https://wandb.ai/burny-burny/huggingface
wandb: ğŸš€ View run at https://wandb.ai/burny-burny/huggingface/runs/zap0zm1t

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SFT Training Started 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

 Max Steps:        10
 Batch Size:       1
 Gradient Accum:   1
 Effective Batch:  1
 Learning Rate:    2.00e-05
 Warmup Steps:     0
 Save Strategy:    SaveStrategy.STEPS (every 5)


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ SFT Training Initialized                                                                                              
â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Max steps: 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Training Arguments 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

                                                                                   TrainingArguments
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                               â”ƒ Value                                                                       
â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ output_dir                              â”‚ runs/20260111_064045_89cu/test-model-sft                                    
â”‚
â”‚ overwrite_output_dir                    â”‚ No                                                                          
â”‚
â”‚ do_train                                â”‚ No                                                                          
â”‚
â”‚ do_eval                                 â”‚ No                                                                          
â”‚
â”‚ do_predict                              â”‚ No                                                                          
â”‚
â”‚ eval_strategy                           â”‚ IntervalStrategy.NO                                                         
â”‚
â”‚ prediction_loss_only                    â”‚ No                                                                          
â”‚
â”‚ per_device_train_batch_size             â”‚ 1                                                                           
â”‚
â”‚ per_device_eval_batch_size              â”‚ 8                                                                           
â”‚
â”‚ per_gpu_train_batch_size                â”‚ None                                                                        
â”‚
â”‚ per_gpu_eval_batch_size                 â”‚ None                                                                        
â”‚
â”‚ gradient_accumulation_steps             â”‚ 1                                                                           
â”‚
â”‚ eval_accumulation_steps                 â”‚ None                                                                        
â”‚
â”‚ eval_delay                              â”‚ 0                                                                           
â”‚
â”‚ torch_empty_cache_steps                 â”‚ None                                                                        
â”‚
â”‚ learning_rate                           â”‚ 2e-05                                                                       
â”‚
â”‚ weight_decay                            â”‚ 0.0                                                                         
â”‚
â”‚ adam_beta1                              â”‚ 0.9                                                                         
â”‚
â”‚ adam_beta2                              â”‚ 0.999                                                                       
â”‚
â”‚ adam_epsilon                            â”‚ 1e-08                                                                       
â”‚
â”‚ max_grad_norm                           â”‚ 1.0                                                                         
â”‚
â”‚ num_train_epochs                        â”‚ 3.0                                                                         
â”‚
â”‚ max_steps                               â”‚ 10                                                                          
â”‚
â”‚ lr_scheduler_type                       â”‚ SchedulerType.LINEAR                                                        
â”‚
â”‚ lr_scheduler_kwargs                     â”‚ None                                                                        
â”‚
â”‚ warmup_ratio                            â”‚ 0.0                                                                         
â”‚
â”‚ warmup_steps                            â”‚ 0                                                                           
â”‚
â”‚ log_level                               â”‚ info                                                                        
â”‚
â”‚ log_level_replica                       â”‚ warning                                                                     
â”‚
â”‚ log_on_each_node                        â”‚ Yes                                                                         
â”‚
â”‚ logging_dir                             â”‚ runs/20260111_064045_89cu/test-model-sft/logs                               
â”‚
â”‚ logging_strategy                        â”‚ IntervalStrategy.STEPS                                                      
â”‚
â”‚ logging_first_step                      â”‚ No                                                                          
â”‚
â”‚ logging_steps                           â”‚ 1                                                                           
â”‚
â”‚ logging_nan_inf_filter                  â”‚ Yes                                                                         
â”‚
â”‚ save_strategy                           â”‚ SaveStrategy.STEPS                                                          
â”‚
â”‚ save_steps                              â”‚ 5                                                                           
â”‚
â”‚ save_total_limit                        â”‚ 2                                                                           
â”‚
â”‚ save_safetensors                        â”‚ Yes                                                                         
â”‚
â”‚ save_on_each_node                       â”‚ No                                                                          
â”‚
â”‚ save_only_model                         â”‚ No                                                                          
â”‚
â”‚ restore_callback_states_from_checkpoint â”‚ No                                                                          
â”‚
â”‚ no_cuda                                 â”‚ No                                                                          
â”‚
â”‚ use_cpu                                 â”‚ No                                                                          
â”‚
â”‚ use_mps_device                          â”‚ No                                                                          
â”‚
â”‚ seed                                    â”‚ 42                                                                          
â”‚
â”‚ data_seed                               â”‚ None                                                                        
â”‚
â”‚ jit_mode_eval                           â”‚ No                                                                          
â”‚
â”‚ bf16                                    â”‚ No                                                                          
â”‚
â”‚ fp16                                    â”‚ No                                                                          
â”‚
â”‚ fp16_opt_level                          â”‚ O1                                                                          
â”‚
â”‚ half_precision_backend                  â”‚ auto                                                                        
â”‚
â”‚ bf16_full_eval                          â”‚ No                                                                          
â”‚
â”‚ fp16_full_eval                          â”‚ No                                                                          
â”‚
â”‚ tf32                                    â”‚ None                                                                        
â”‚
â”‚ local_rank                              â”‚ 0                                                                           
â”‚
â”‚ ddp_backend                             â”‚ None                                                                        
â”‚
â”‚ tpu_num_cores                           â”‚ None                                                                        
â”‚
â”‚ tpu_metrics_debug                       â”‚ No                                                                          
â”‚
â”‚ debug                                   â”‚                                                                             
â”‚
â”‚ dataloader_drop_last                    â”‚ No                                                                          
â”‚
â”‚ eval_steps                              â”‚ None                                                                        
â”‚
â”‚ dataloader_num_workers                  â”‚ 0                                                                           
â”‚
â”‚ dataloader_prefetch_factor              â”‚ None                                                                        
â”‚
â”‚ past_index                              â”‚ -1                                                                          
â”‚
â”‚ run_name                                â”‚ None                                                                        
â”‚
â”‚ disable_tqdm                            â”‚ No                                                                          
â”‚
â”‚ remove_unused_columns                   â”‚ Yes                                                                         
â”‚
â”‚ label_names                             â”‚ None                                                                        
â”‚
â”‚ load_best_model_at_end                  â”‚ No                                                                          
â”‚
â”‚ metric_for_best_model                   â”‚ None                                                                        
â”‚
â”‚ greater_is_better                       â”‚ None                                                                        
â”‚
â”‚ ignore_data_skip                        â”‚ No                                                                          
â”‚
â”‚ fsdp                                    â”‚                                                                             
â”‚
â”‚ fsdp_min_num_params                     â”‚ 0                                                                           
â”‚
â”‚ fsdp_config                             â”‚ {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 
'xla_fsdp_grad_ckpt': False}                                                    â”‚
â”‚ fsdp_transformer_layer_cls_to_wrap      â”‚ None                                                                        
â”‚
â”‚ accelerator_config                      â”‚ AcceleratorConfig(split_batches=False, dispatch_batches=None, 
even_batches=True, use_seedable_sampler=True, non_blocking=False,           â”‚
â”‚                                         â”‚ gradient_accumulation_kwargs=None, use_configured_state=False)              
â”‚
â”‚ parallelism_config                      â”‚ None                                                                        
â”‚
â”‚ deepspeed                               â”‚ None                                                                        
â”‚
â”‚ label_smoothing_factor                  â”‚ 0.0                                                                         
â”‚
â”‚ optim                                   â”‚ OptimizerNames.ADAMW_TORCH_FUSED                                            
â”‚
â”‚ optim_args                              â”‚ None                                                                        
â”‚
â”‚ adafactor                               â”‚ No                                                                          
â”‚
â”‚ group_by_length                         â”‚ No                                                                          
â”‚
â”‚ length_column_name                      â”‚ length                                                                      
â”‚
â”‚ report_to                               â”‚ wandb                                                                       
â”‚
â”‚ project                                 â”‚ huggingface                                                                 
â”‚
â”‚ trackio_space_id                        â”‚ trackio                                                                     
â”‚
â”‚ ddp_find_unused_parameters              â”‚ None                                                                        
â”‚
â”‚ ddp_bucket_cap_mb                       â”‚ None                                                                        
â”‚
â”‚ ddp_broadcast_buffers                   â”‚ None                                                                        
â”‚
â”‚ dataloader_pin_memory                   â”‚ No                                                                          
â”‚
â”‚ dataloader_persistent_workers           â”‚ No                                                                          
â”‚
â”‚ skip_memory_metrics                     â”‚ Yes                                                                         
â”‚
â”‚ use_legacy_prediction_loop              â”‚ No                                                                          
â”‚
â”‚ push_to_hub                             â”‚ No                                                                          
â”‚
â”‚ resume_from_checkpoint                  â”‚ None                                                                        
â”‚
â”‚ hub_model_id                            â”‚ None                                                                        
â”‚
â”‚ hub_strategy                            â”‚ HubStrategy.EVERY_SAVE                                                      
â”‚
â”‚ hub_token                               â”‚ None                                                                        
â”‚
â”‚ hub_private_repo                        â”‚ None                                                                        
â”‚
â”‚ hub_always_push                         â”‚ No                                                                          
â”‚
â”‚ hub_revision                            â”‚ None                                                                        
â”‚
â”‚ gradient_checkpointing                  â”‚ No                                                                          
â”‚
â”‚ gradient_checkpointing_kwargs           â”‚ None                                                                        
â”‚
â”‚ include_inputs_for_metrics              â”‚ No                                                                          
â”‚
â”‚ include_for_metrics                     â”‚                                                                             
â”‚
â”‚ eval_do_concat_batches                  â”‚ Yes                                                                         
â”‚
â”‚ fp16_backend                            â”‚ auto                                                                        
â”‚
â”‚ push_to_hub_model_id                    â”‚ None                                                                        
â”‚
â”‚ push_to_hub_organization                â”‚ None                                                                        
â”‚
â”‚ push_to_hub_token                       â”‚ None                                                                        
â”‚
â”‚ mp_parameters                           â”‚                                                                             
â”‚
â”‚ auto_find_batch_size                    â”‚ No                                                                          
â”‚
â”‚ full_determinism                        â”‚ No                                                                          
â”‚
â”‚ torchdynamo                             â”‚ None                                                                        
â”‚
â”‚ ray_scope                               â”‚ last                                                                        
â”‚
â”‚ ddp_timeout                             â”‚ 1800                                                                        
â”‚
â”‚ torch_compile                           â”‚ No                                                                          
â”‚
â”‚ torch_compile_backend                   â”‚ None                                                                        
â”‚
â”‚ torch_compile_mode                      â”‚ None                                                                        
â”‚
â”‚ include_tokens_per_second               â”‚ No                                                                          
â”‚
â”‚ include_num_input_tokens_seen           â”‚ no                                                                          
â”‚
â”‚ neftune_noise_alpha                     â”‚ None                                                                        
â”‚
â”‚ optim_target_modules                    â”‚ None                                                                        
â”‚
â”‚ batch_eval_metrics                      â”‚ No                                                                          
â”‚
â”‚ eval_on_start                           â”‚ No                                                                          
â”‚
â”‚ use_liger_kernel                        â”‚ No                                                                          
â”‚
â”‚ liger_kernel_config                     â”‚ None                                                                        
â”‚
â”‚ eval_use_gather_object                  â”‚ No                                                                          
â”‚
â”‚ average_tokens_across_devices           â”‚ Yes                                                                         
â”‚
â”‚ model_init_kwargs                       â”‚ None                                                                        
â”‚
â”‚ chat_template_path                      â”‚ None                                                                        
â”‚
â”‚ dataset_text_field                      â”‚ text                                                                        
â”‚
â”‚ dataset_kwargs                          â”‚ None                                                                        
â”‚
â”‚ dataset_num_proc                        â”‚ None                                                                        
â”‚
â”‚ eos_token                               â”‚ None                                                                        
â”‚
â”‚ pad_token                               â”‚ None                                                                        
â”‚
â”‚ max_length                              â”‚ 1024                                                                        
â”‚
â”‚ shuffle_dataset                         â”‚ No                                                                          
â”‚
â”‚ packing                                 â”‚ No                                                                          
â”‚
â”‚ packing_strategy                        â”‚ bfd                                                                         
â”‚
â”‚ padding_free                            â”‚ No                                                                          
â”‚
â”‚ pad_to_multiple_of                      â”‚ None                                                                        
â”‚
â”‚ eval_packing                            â”‚ None                                                                        
â”‚
â”‚ completion_only_loss                    â”‚ None                                                                        
â”‚
â”‚ assistant_only_loss                     â”‚ No                                                                          
â”‚
â”‚ loss_type                               â”‚ nll                                                                         
â”‚
â”‚ activation_offloading                   â”‚ No                                                                          
â”‚
â”‚ distributed_state                       â”‚ Distributed environment: DistributedType.NO                                 
â”‚
â”‚                                         â”‚ Num processes: 1                                                            
â”‚
â”‚                                         â”‚ Process index: 0                                                            
â”‚
â”‚                                         â”‚ Local process index: 0                                                      
â”‚
â”‚                                         â”‚ Device: cuda                                                                
â”‚
â”‚                                         â”‚                                                                             
â”‚
â”‚ deepspeed_plugin                        â”‚ None                                                                        
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


  0%|          | 0/10 [00:00<?, ?it/s]
 10%|â–ˆ         | 1/10 [00:02<00:21,  2.34s/it]    Step 1: loss: 1.6952 | lr: 2.00e-05 | grad: 2.28 | epoch: 0.10 | GPU: 
1.5/8.0GB
  Step 1/10 (10.0%) loss=1.6952 | lr=2.00e-05 | grad=2.284
  GPU 0: 1.55GB allocated / 3.81GB reserved / 8.0GB total



 10%|â–ˆ         | 1/10 [00:02<00:21,  2.34s/it]
 20%|â–ˆâ–ˆ        | 2/10 [00:02<00:09,  1.17s/it]{'loss': 1.6952, 'grad_norm': 2.284175395965576, 'learning_rate': 2e-05, 
'entropy': 1.570913314819336, 'num_tokens': 1024.0, 'mean_token_accuracy': 0.6099706888198853, 'epoch': 0.1}
  Step 2/10 (20.0%) loss=1.6732 | lr=1.80e-05 | grad=2.223
  GPU 0: 1.55GB allocated / 4.31GB reserved / 8.0GB total



 20%|â–ˆâ–ˆ        | 2/10 [00:02<00:09,  1.17s/it]
 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:03<00:05,  1.22it/s]{'loss': 1.6732, 'grad_norm': 2.222827434539795, 'learning_rate': 1.8e-05,
'entropy': 1.5737276077270508, 'num_tokens': 1924.0, 'mean_token_accuracy': 0.6106785535812378, 'epoch': 0.2}
  Step 3/10 (30.0%) loss=2.4414 | lr=1.60e-05 | grad=7.813
  GPU 0: 1.55GB allocated / 4.43GB reserved / 8.0GB total



 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:03<00:05,  1.22it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:03<00:03,  1.58it/s]{'loss': 2.4414, 'grad_norm': 7.812869548797607, 'learning_rate': 
1.6000000000000003e-05, 'entropy': 1.8525969982147217, 'num_tokens': 2032.0, 'mean_token_accuracy': 0.4579439163208008, 
'epoch': 0.3}
  Step 4/10 (40.0%) loss=2.1556 | lr=1.40e-05 | grad=4.228
  GPU 0: 1.55GB allocated / 4.57GB reserved / 8.0GB total



 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:03<00:03,  1.58it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:03<00:02,  1.87it/s]{'loss': 2.1556, 'grad_norm': 4.227725028991699, 'learning_rate': 1.4e-05,
'entropy': 1.9018568992614746, 'num_tokens': 2382.0, 'mean_token_accuracy': 0.5472779273986816, 'epoch': 0.4}
  Step 5/10 (50.0%) loss=1.6564 | lr=1.20e-05 | grad=2.088
  GPU 0: 1.55GB allocated / 5.13GB reserved / 8.0GB total



 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:03<00:02,  1.87it/s]Saving model checkpoint to 
runs/20260111_064045_89cu/test-model-sft/checkpoint-5
Configuration saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-5/config.json
Configuration saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-5/generation_config.json
Model weights saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-5/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-5/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-5/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-5/special_tokens_map.json
{'loss': 1.6564, 'grad_norm': 2.088064193725586, 'learning_rate': 1.2e-05, 'entropy': 1.4690934419631958, 'num_tokens': 
3406.0, 'mean_token_accuracy': 0.6637341380119324, 'epoch': 0.5}
    âœ“ Checkpoint saved at step 5
  âœ“ Checkpoint saved at step 5 â†’ runs/20260111_064045_89cu/test-model-sft

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:13<00:14,  3.70s/it]    Step 6: loss: 1.3020 | lr: 1.00e-05 | grad: 3.27 | epoch: 0.60 | GPU: 
1.5/8.0GB
  Step 6/10 (60.0%) loss=1.3020 | lr=1.00e-05 | grad=3.267
  GPU 0: 1.55GB allocated / 5.13GB reserved / 8.0GB total



 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:13<00:14,  3.70s/it]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:13<00:07,  2.59s/it]{'loss': 1.302, 'grad_norm': 3.2672746181488037, 'learning_rate': 1e-05, 
'entropy': 1.066642165184021, 'num_tokens': 3898.0, 'mean_token_accuracy': 0.6496945023536682, 'epoch': 0.6}
  Step 7/10 (70.0%) loss=1.8940 | lr=8.00e-06 | grad=2.521
  GPU 0: 1.55GB allocated / 5.13GB reserved / 8.0GB total



 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:13<00:07,  2.59s/it]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:14<00:03,  1.85s/it]{'loss': 1.894, 'grad_norm': 2.5210258960723877, 'learning_rate': 
8.000000000000001e-06, 'entropy': 1.8343291282653809, 'num_tokens': 4918.0, 'mean_token_accuracy': 0.5475956797599792, 
'epoch': 0.7}
  Step 8/10 (80.0%) loss=1.5194 | lr=6.00e-06 | grad=3.214
  GPU 0: 1.55GB allocated / 5.14GB reserved / 8.0GB total



 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:14<00:03,  1.85s/it]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:14<00:01,  1.37s/it]{'loss': 1.5194, 'grad_norm': 3.214379072189331, 'learning_rate': 6e-06, 
'entropy': 1.3005387783050537, 'num_tokens': 5355.0, 'mean_token_accuracy': 0.6376146674156189, 'epoch': 0.8}
  Step 9/10 (90.0%) loss=1.9235 | lr=4.00e-06 | grad=2.401
  GPU 0: 1.55GB allocated / 5.14GB reserved / 8.0GB total



 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:14<00:01,  1.37s/it]{'loss': 1.9235, 'grad_norm': 2.401282787322998, 'learning_rate': 
4.000000000000001e-06, 'entropy': 1.9367377758026123, 'num_tokens': 6341.0, 'mean_token_accuracy': 0.5847715735435486, 
'epoch': 0.9}
  Step 10 | 0.238s/step | avg: 0.481s | ETA: 0.0s

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.03s/it]  Step 10/10 (100.0%) loss=2.1224 | lr=2.00e-06 | grad=3.839
  GPU 0: 1.55GB allocated / 5.14GB reserved / 8.0GB total



100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.03s/it]Saving model checkpoint to 
runs/20260111_064045_89cu/test-model-sft/checkpoint-10
Configuration saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-10/config.json
Configuration saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-10/generation_config.json
Model weights saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-10/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-10/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-10/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-sft/checkpoint-10/special_tokens_map.json
{'loss': 2.1224, 'grad_norm': 3.8387115001678467, 'learning_rate': 2.0000000000000003e-06, 'entropy': 2.062127113342285,
'num_tokens': 6850.0, 'mean_token_accuracy': 0.5807086825370789, 'epoch': 1.0}
    âœ“ Checkpoint saved at step 10
  âœ“ Checkpoint saved at step 10 â†’ runs/20260111_064045_89cu/test-model-sft


Training completed. Do not forget to share your model on huggingface.co/models =)


    Step 10: loss: 1.8383 | epoch: 1.00 | GPU: 1.5/8.0GB
  Step 10/10 (100.0%)
  GPU 0: 1.55GB allocated / 5.14GB reserved / 8.0GB total



100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  1.03s/it]{'train_runtime': 26.1101, 'train_samples_per_second': 0.383, 
'train_steps_per_second': 0.383, 'train_loss': 1.8383063912391662, 'epoch': 1.0}
  SFT â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 10/10 | 0:00:14 < 0:00:00


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SFT Training Complete 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Total Steps:   10
 Total Epochs:  1.00
 Duration:      24.1s
 Steps/sec:     0.41
 Final Loss:    1.8383


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ SFT Training Complete!                                                                                                
â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Total steps: 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
  Average step time: 0.481s
  Total steps: 10
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Training   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00                                                      
â”‚
â”‚ â ‹ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Step 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚
â”‚   â”‚ 
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚ â”‚
â”‚   â”‚ â”‚  Metric                                Value                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_runtime                        26.110                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_samples_per_second              0.383                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_steps_per_second                0.383                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  total_flos                4364962041600.000                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_loss                            1.838                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  epoch                                 1.000                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ 
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚ â”‚
â”‚   
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.40s/it]

Saving SFT model to: runs/20260111_064045_89cu/test-model-sft
Saving model checkpoint to runs/20260111_064045_89cu/test-model-sft
Configuration saved in runs/20260111_064045_89cu/test-model-sft/config.json
Configuration saved in runs/20260111_064045_89cu/test-model-sft/generation_config.json
Model weights saved in runs/20260111_064045_89cu/test-model-sft/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-sft/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-sft/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-sft/special_tokens_map.json

âœ“ SFT model saved to runs/20260111_064045_89cu/test-model-sft
âœ“ SFT completed in 35.2s
   âœ“ SFT Training
     Completed
â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ Metric   â”ƒ Value â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ Duration â”‚ 35.2s â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜



â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ REWARD Training 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â„¹ Model: HuggingFaceTB/SmolLM2-135M-Instruct
â„¹ Dataset: trl-lib/ultrafeedback_binarized
â„¹ Output: runs/20260111_064045_89cu/test-model-reward
â„¹ Output directory ready: runs/20260111_064045_89cu/test-model-reward
[06:41:20] INFO     Starting Reward training with model=HuggingFaceTB/SmolLM2-135M-Instruct                             
reward.py:43
Loading dataset: trl-lib/ultrafeedback_binarized (split: train)

â„¹ Limited dataset from 62,135 to 10 samples
                      Dataset Information
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Property    â”ƒ Value                                          â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Dataset     â”‚ trl-lib/ultrafeedback_binarized                â”‚
â”‚ Samples     â”‚ 10                                             â”‚
â”‚ Columns     â”‚ chosen, rejected, score_chosen, score_rejected â”‚
â”‚ Sample Keys â”‚ chosen, rejected, score_chosen                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â„¹ Loading model as SequenceClassification: HuggingFaceTB/SmolLM2-135M-Instruct
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at 
HuggingFaceTB/SmolLM2-135M-Instruct and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

                      Model Information
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Property             â”ƒ Value                               â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Model Name           â”‚ HuggingFaceTB/SmolLM2-135M-Instruct â”‚
â”‚ Architecture         â”‚ LlamaForCausalLM                    â”‚
â”‚ Hidden Size          â”‚ 576                                 â”‚
â”‚ Layers               â”‚ 30                                  â”‚
â”‚ Attention Heads      â”‚ 9                                   â”‚
â”‚ Vocab Size           â”‚ 49,152                              â”‚
â”‚ Total Parameters     â”‚ 134,515,584                         â”‚
â”‚ Trainable Parameters â”‚ 134,515,584                         â”‚
â”‚ Trainable %          â”‚ 100.00%                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â„¹ Creating Reward trainer...

Tokenizing train dataset:   0%|          | 0/10 [00:00<?, ? examples/s]
Tokenizing train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 101.03 examples/s]

Filtering train >1024 tokens:   0%|          | 0/10 [00:00<?, ? examples/s]
Filtering train >1024 tokens: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 434.13 examples/s]
max_steps is given, it will override any value given in num_train_epochs
Starting Reward training loop...
The following columns in the Training set don't have a corresponding argument in 
`LlamaForSequenceClassification.forward` and have been ignored: score_rejected, score_chosen, rejected, chosen. If 
score_rejected, score_chosen, rejected, chosen are not expected by `LlamaForSequenceClassification.forward`,  you can 
safely ignore this message.
***** Running training *****
  Num examples = 9
  Num Epochs = 2
  Instantaneous batch size per device = 1
  Total train batch size (w. parallel, distributed & accumulation) = 1
  Gradient Accumulation steps = 1
  Total optimization steps = 10
  Number of trainable parameters = 134,515,584
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Reward Training Started 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

 Max Steps:        10
 Batch Size:       1
 Gradient Accum:   1
 Effective Batch:  1
 Learning Rate:    1.00e-04
 Warmup Steps:     0
 Save Strategy:    SaveStrategy.STEPS (every 5)


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Reward Training Initialized                                                                                           
â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Max steps: 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Training Arguments 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

                                                                                   TrainingArguments
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                               â”ƒ Value                                                                       
â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ output_dir                              â”‚ runs/20260111_064045_89cu/test-model-reward                                 
â”‚
â”‚ overwrite_output_dir                    â”‚ No                                                                          
â”‚
â”‚ do_train                                â”‚ No                                                                          
â”‚
â”‚ do_eval                                 â”‚ No                                                                          
â”‚
â”‚ do_predict                              â”‚ No                                                                          
â”‚
â”‚ eval_strategy                           â”‚ IntervalStrategy.NO                                                         
â”‚
â”‚ prediction_loss_only                    â”‚ No                                                                          
â”‚
â”‚ per_device_train_batch_size             â”‚ 1                                                                           
â”‚
â”‚ per_device_eval_batch_size              â”‚ 8                                                                           
â”‚
â”‚ per_gpu_train_batch_size                â”‚ None                                                                        
â”‚
â”‚ per_gpu_eval_batch_size                 â”‚ None                                                                        
â”‚
â”‚ gradient_accumulation_steps             â”‚ 1                                                                           
â”‚
â”‚ eval_accumulation_steps                 â”‚ None                                                                        
â”‚
â”‚ eval_delay                              â”‚ 0                                                                           
â”‚
â”‚ torch_empty_cache_steps                 â”‚ None                                                                        
â”‚
â”‚ learning_rate                           â”‚ 0.0001                                                                      
â”‚
â”‚ weight_decay                            â”‚ 0.0                                                                         
â”‚
â”‚ adam_beta1                              â”‚ 0.9                                                                         
â”‚
â”‚ adam_beta2                              â”‚ 0.999                                                                       
â”‚
â”‚ adam_epsilon                            â”‚ 1e-08                                                                       
â”‚
â”‚ max_grad_norm                           â”‚ 1.0                                                                         
â”‚
â”‚ num_train_epochs                        â”‚ 3.0                                                                         
â”‚
â”‚ max_steps                               â”‚ 10                                                                          
â”‚
â”‚ lr_scheduler_type                       â”‚ SchedulerType.LINEAR                                                        
â”‚
â”‚ lr_scheduler_kwargs                     â”‚ None                                                                        
â”‚
â”‚ warmup_ratio                            â”‚ 0.0                                                                         
â”‚
â”‚ warmup_steps                            â”‚ 0                                                                           
â”‚
â”‚ log_level                               â”‚ info                                                                        
â”‚
â”‚ log_level_replica                       â”‚ warning                                                                     
â”‚
â”‚ log_on_each_node                        â”‚ Yes                                                                         
â”‚
â”‚ logging_dir                             â”‚ runs/20260111_064045_89cu/test-model-reward/logs                            
â”‚
â”‚ logging_strategy                        â”‚ IntervalStrategy.STEPS                                                      
â”‚
â”‚ logging_first_step                      â”‚ No                                                                          
â”‚
â”‚ logging_steps                           â”‚ 1                                                                           
â”‚
â”‚ logging_nan_inf_filter                  â”‚ Yes                                                                         
â”‚
â”‚ save_strategy                           â”‚ SaveStrategy.STEPS                                                          
â”‚
â”‚ save_steps                              â”‚ 5                                                                           
â”‚
â”‚ save_total_limit                        â”‚ 2                                                                           
â”‚
â”‚ save_safetensors                        â”‚ Yes                                                                         
â”‚
â”‚ save_on_each_node                       â”‚ No                                                                          
â”‚
â”‚ save_only_model                         â”‚ No                                                                          
â”‚
â”‚ restore_callback_states_from_checkpoint â”‚ No                                                                          
â”‚
â”‚ no_cuda                                 â”‚ No                                                                          
â”‚
â”‚ use_cpu                                 â”‚ No                                                                          
â”‚
â”‚ use_mps_device                          â”‚ No                                                                          
â”‚
â”‚ seed                                    â”‚ 42                                                                          
â”‚
â”‚ data_seed                               â”‚ None                                                                        
â”‚
â”‚ jit_mode_eval                           â”‚ No                                                                          
â”‚
â”‚ bf16                                    â”‚ No                                                                          
â”‚
â”‚ fp16                                    â”‚ No                                                                          
â”‚
â”‚ fp16_opt_level                          â”‚ O1                                                                          
â”‚
â”‚ half_precision_backend                  â”‚ auto                                                                        
â”‚
â”‚ bf16_full_eval                          â”‚ No                                                                          
â”‚
â”‚ fp16_full_eval                          â”‚ No                                                                          
â”‚
â”‚ tf32                                    â”‚ None                                                                        
â”‚
â”‚ local_rank                              â”‚ 0                                                                           
â”‚
â”‚ ddp_backend                             â”‚ None                                                                        
â”‚
â”‚ tpu_num_cores                           â”‚ None                                                                        
â”‚
â”‚ tpu_metrics_debug                       â”‚ No                                                                          
â”‚
â”‚ debug                                   â”‚                                                                             
â”‚
â”‚ dataloader_drop_last                    â”‚ No                                                                          
â”‚
â”‚ eval_steps                              â”‚ None                                                                        
â”‚
â”‚ dataloader_num_workers                  â”‚ 0                                                                           
â”‚
â”‚ dataloader_prefetch_factor              â”‚ None                                                                        
â”‚
â”‚ past_index                              â”‚ -1                                                                          
â”‚
â”‚ run_name                                â”‚ None                                                                        
â”‚
â”‚ disable_tqdm                            â”‚ No                                                                          
â”‚
â”‚ remove_unused_columns                   â”‚ Yes                                                                         
â”‚
â”‚ label_names                             â”‚ None                                                                        
â”‚
â”‚ load_best_model_at_end                  â”‚ No                                                                          
â”‚
â”‚ metric_for_best_model                   â”‚ None                                                                        
â”‚
â”‚ greater_is_better                       â”‚ None                                                                        
â”‚
â”‚ ignore_data_skip                        â”‚ No                                                                          
â”‚
â”‚ fsdp                                    â”‚                                                                             
â”‚
â”‚ fsdp_min_num_params                     â”‚ 0                                                                           
â”‚
â”‚ fsdp_config                             â”‚ {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 
'xla_fsdp_grad_ckpt': False}                                                    â”‚
â”‚ fsdp_transformer_layer_cls_to_wrap      â”‚ None                                                                        
â”‚
â”‚ accelerator_config                      â”‚ AcceleratorConfig(split_batches=False, dispatch_batches=None, 
even_batches=True, use_seedable_sampler=True, non_blocking=False,           â”‚
â”‚                                         â”‚ gradient_accumulation_kwargs=None, use_configured_state=False)              
â”‚
â”‚ parallelism_config                      â”‚ None                                                                        
â”‚
â”‚ deepspeed                               â”‚ None                                                                        
â”‚
â”‚ label_smoothing_factor                  â”‚ 0.0                                                                         
â”‚
â”‚ optim                                   â”‚ OptimizerNames.ADAMW_TORCH_FUSED                                            
â”‚
â”‚ optim_args                              â”‚ None                                                                        
â”‚
â”‚ adafactor                               â”‚ No                                                                          
â”‚
â”‚ group_by_length                         â”‚ No                                                                          
â”‚
â”‚ length_column_name                      â”‚ length                                                                      
â”‚
â”‚ report_to                               â”‚ wandb                                                                       
â”‚
â”‚ project                                 â”‚ huggingface                                                                 
â”‚
â”‚ trackio_space_id                        â”‚ trackio                                                                     
â”‚
â”‚ ddp_find_unused_parameters              â”‚ None                                                                        
â”‚
â”‚ ddp_bucket_cap_mb                       â”‚ None                                                                        
â”‚
â”‚ ddp_broadcast_buffers                   â”‚ None                                                                        
â”‚
â”‚ dataloader_pin_memory                   â”‚ No                                                                          
â”‚
â”‚ dataloader_persistent_workers           â”‚ No                                                                          
â”‚
â”‚ skip_memory_metrics                     â”‚ Yes                                                                         
â”‚
â”‚ use_legacy_prediction_loop              â”‚ No                                                                          
â”‚
â”‚ push_to_hub                             â”‚ No                                                                          
â”‚
â”‚ resume_from_checkpoint                  â”‚ None                                                                        
â”‚
â”‚ hub_model_id                            â”‚ None                                                                        
â”‚
â”‚ hub_strategy                            â”‚ HubStrategy.EVERY_SAVE                                                      
â”‚
â”‚ hub_token                               â”‚ None                                                                        
â”‚
â”‚ hub_private_repo                        â”‚ None                                                                        
â”‚
â”‚ hub_always_push                         â”‚ No                                                                          
â”‚
â”‚ hub_revision                            â”‚ None                                                                        
â”‚
â”‚ gradient_checkpointing                  â”‚ No                                                                          
â”‚
â”‚ gradient_checkpointing_kwargs           â”‚ None                                                                        
â”‚
â”‚ include_inputs_for_metrics              â”‚ No                                                                          
â”‚
â”‚ include_for_metrics                     â”‚                                                                             
â”‚
â”‚ eval_do_concat_batches                  â”‚ Yes                                                                         
â”‚
â”‚ fp16_backend                            â”‚ auto                                                                        
â”‚
â”‚ push_to_hub_model_id                    â”‚ None                                                                        
â”‚
â”‚ push_to_hub_organization                â”‚ None                                                                        
â”‚
â”‚ push_to_hub_token                       â”‚ None                                                                        
â”‚
â”‚ mp_parameters                           â”‚                                                                             
â”‚
â”‚ auto_find_batch_size                    â”‚ No                                                                          
â”‚
â”‚ full_determinism                        â”‚ No                                                                          
â”‚
â”‚ torchdynamo                             â”‚ None                                                                        
â”‚
â”‚ ray_scope                               â”‚ last                                                                        
â”‚
â”‚ ddp_timeout                             â”‚ 1800                                                                        
â”‚
â”‚ torch_compile                           â”‚ No                                                                          
â”‚
â”‚ torch_compile_backend                   â”‚ None                                                                        
â”‚
â”‚ torch_compile_mode                      â”‚ None                                                                        
â”‚
â”‚ include_tokens_per_second               â”‚ No                                                                          
â”‚
â”‚ include_num_input_tokens_seen           â”‚ no                                                                          
â”‚
â”‚ neftune_noise_alpha                     â”‚ None                                                                        
â”‚
â”‚ optim_target_modules                    â”‚ None                                                                        
â”‚
â”‚ batch_eval_metrics                      â”‚ No                                                                          
â”‚
â”‚ eval_on_start                           â”‚ No                                                                          
â”‚
â”‚ use_liger_kernel                        â”‚ No                                                                          
â”‚
â”‚ liger_kernel_config                     â”‚ None                                                                        
â”‚
â”‚ eval_use_gather_object                  â”‚ No                                                                          
â”‚
â”‚ average_tokens_across_devices           â”‚ Yes                                                                         
â”‚
â”‚ model_init_kwargs                       â”‚ None                                                                        
â”‚
â”‚ chat_template_path                      â”‚ None                                                                        
â”‚
â”‚ disable_dropout                         â”‚ Yes                                                                         
â”‚
â”‚ dataset_num_proc                        â”‚ None                                                                        
â”‚
â”‚ eos_token                               â”‚ None                                                                        
â”‚
â”‚ pad_token                               â”‚ None                                                                        
â”‚
â”‚ max_length                              â”‚ 1024                                                                        
â”‚
â”‚ pad_to_multiple_of                      â”‚ None                                                                        
â”‚
â”‚ center_rewards_coefficient              â”‚ None                                                                        
â”‚
â”‚ activation_offloading                   â”‚ No                                                                          
â”‚
â”‚ distributed_state                       â”‚ Distributed environment: DistributedType.NO                                 
â”‚
â”‚                                         â”‚ Num processes: 1                                                            
â”‚
â”‚                                         â”‚ Process index: 0                                                            
â”‚
â”‚                                         â”‚ Local process index: 0                                                      
â”‚
â”‚                                         â”‚ Device: cuda                                                                
â”‚
â”‚                                         â”‚                                                                             
â”‚
â”‚ deepspeed_plugin                        â”‚ None                                                                        
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


  0%|          | 0/10 [00:00<?, ?it/s]
 10%|â–ˆ         | 1/10 [00:00<00:08,  1.03it/s]    Step 1: loss: 0.3451 | lr: 1.00e-04 | grad: 14.95 | epoch: 0.11 | GPU:
1.5/8.0GB
  Step 1/10 (10.0%) loss=0.3451 | lr=1.00e-04 | grad=14.945
  GPU 0: 1.54GB allocated / 2.12GB reserved / 8.0GB total



 10%|â–ˆ         | 1/10 [00:00<00:08,  1.03it/s]
 20%|â–ˆâ–ˆ        | 2/10 [00:01<00:04,  1.65it/s]{'loss': 0.3451, 'grad_norm': 14.945466041564941, 'learning_rate': 0.0001,
'num_tokens': 525.0, 'min_reward': -0.6409338116645813, 'mean_reward': -0.1977921426296234, 'max_reward': 
0.24534952640533447, 'accuracy': 1.0, 'margin': 0.8862833380699158, 'epoch': 0.11}
  Step 2/10 (20.0%) loss=0.3213 | lr=9.00e-05 | grad=20.166
  GPU 0: 1.54GB allocated / 2.74GB reserved / 8.0GB total



 20%|â–ˆâ–ˆ        | 2/10 [00:01<00:04,  1.65it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:01<00:03,  1.87it/s]{'loss': 0.3213, 'grad_norm': 20.16575813293457, 'learning_rate': 9e-05, 
'num_tokens': 1310.0, 'min_reward': -1.3375637531280518, 'mean_reward': -0.8522842526435852, 'max_reward': 
-0.36700475215911865, 'accuracy': 1.0, 'margin': 0.9705590009689331, 'epoch': 0.22}
  Step 3/10 (30.0%) loss=0.4142 | lr=8.00e-05 | grad=17.365
  GPU 0: 1.54GB allocated / 4.82GB reserved / 8.0GB total



 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:01<00:03,  1.87it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:02<00:02,  2.01it/s]{'loss': 0.4142, 'grad_norm': 17.365360260009766, 'learning_rate': 8e-05, 
'num_tokens': 3236.0, 'min_reward': -4.706271171569824, 'mean_reward': -4.37275505065918, 'max_reward': 
-4.039238929748535, 'accuracy': 1.0, 'margin': 0.6670322418212891, 'epoch': 0.33}
  Step 4/10 (40.0%) loss=3.8484 | lr=7.00e-05 | grad=148.615
  GPU 0: 1.54GB allocated / 5.09GB reserved / 8.0GB total



 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:02<00:02,  2.01it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:02<00:02,  2.25it/s]{'loss': 3.8484, 'grad_norm': 148.61544799804688, 'learning_rate': 7e-05, 
'num_tokens': 3476.0, 'min_reward': -5.7893385887146, 'mean_reward': -3.8759169578552246, 'max_reward': 
-1.9624955654144287, 'accuracy': 0.0, 'margin': -3.826843023300171, 'epoch': 0.44}
  Step 5/10 (50.0%) loss=1.3625 | lr=6.00e-05 | grad=101.752
  GPU 0: 1.54GB allocated / 5.09GB reserved / 8.0GB total



 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:02<00:02,  2.25it/s]Saving model checkpoint to 
runs/20260111_064045_89cu/test-model-reward/checkpoint-5
Configuration saved in runs/20260111_064045_89cu/test-model-reward/checkpoint-5/config.json
Model weights saved in runs/20260111_064045_89cu/test-model-reward/checkpoint-5/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-reward/checkpoint-5/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-reward/checkpoint-5/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-reward/checkpoint-5/special_tokens_map.json
{'loss': 1.3625, 'grad_norm': 101.75242614746094, 'learning_rate': 6e-05, 'num_tokens': 4677.0, 'min_reward': 
-4.423905372619629, 'mean_reward': -3.890501022338867, 'max_reward': -3.3570964336395264, 'accuracy': 0.0, 'margin': 
-1.0668089389801025, 'epoch': 0.56}
    âœ“ Checkpoint saved at step 5
  âœ“ Checkpoint saved at step 5 â†’ runs/20260111_064045_89cu/test-model-reward

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:08<00:08,  2.25s/it]    Step 6: loss: 0.0386 | lr: 5.00e-05 | grad: 5.92 | epoch: 0.67 | GPU: 
1.5/8.0GB
  Step 6/10 (60.0%) loss=0.0386 | lr=5.00e-05 | grad=5.923
  GPU 0: 1.54GB allocated / 5.09GB reserved / 8.0GB total



 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:08<00:08,  2.25s/it]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:08<00:04,  1.62s/it]{'loss': 0.0386, 'grad_norm': 5.923389911651611, 'learning_rate': 5e-05, 
'num_tokens': 6011.0, 'min_reward': -3.1353235244750977, 'mean_reward': -1.517456293106079, 'max_reward': 
0.10041087865829468, 'accuracy': 1.0, 'margin': 3.235734462738037, 'epoch': 0.67}
  Step 7/10 (70.0%) loss=0.7503 | lr=4.00e-05 | grad=48.079
  GPU 0: 1.54GB allocated / 5.09GB reserved / 8.0GB total



 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:08<00:04,  1.62s/it]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:08<00:02,  1.19s/it]{'loss': 0.7503, 'grad_norm': 48.07902526855469, 'learning_rate': 4e-05, 
'num_tokens': 7457.0, 'min_reward': -1.053794503211975, 'mean_reward': -0.9981496334075928, 'max_reward': 
-0.9425047636032104, 'accuracy': 0.0, 'margin': -0.11128973960876465, 'epoch': 0.78}
  Step 8/10 (80.0%) loss=0.0782 | lr=3.00e-05 | grad=9.477
  GPU 0: 1.54GB allocated / 5.09GB reserved / 8.0GB total



 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:08<00:02,  1.19s/it]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:09<00:00,  1.12it/s]{'loss': 0.0782, 'grad_norm': 9.477279663085938, 'learning_rate': 3e-05, 
'num_tokens': 8910.0, 'min_reward': -2.8255538940429688, 'mean_reward': -1.5708365440368652, 'max_reward': 
-0.31611931324005127, 'accuracy': 1.0, 'margin': 2.509434700012207, 'epoch': 0.89}
  Step 9/10 (90.0%) loss=1.1264 | lr=2.00e-05 | grad=246.160
  GPU 0: 1.54GB allocated / 5.09GB reserved / 8.0GB total



 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:09<00:00,  1.12it/s]{'loss': 1.1264, 'grad_norm': 246.15985107421875, 'learning_rate': 2e-05, 
'num_tokens': 9716.0, 'min_reward': -2.780552625656128, 'mean_reward': -2.413252353668213, 'max_reward': 
-2.0459518432617188, 'accuracy': 0.0, 'margin': -0.7346007823944092, 'epoch': 1.0}
  Step 10 | 0.198s/step | avg: 0.366s | ETA: 0.0s

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.45it/s]  Step 10/10 (100.0%) loss=0.6342 | lr=1.00e-05 | grad=62.141
  GPU 0: 1.54GB allocated / 5.09GB reserved / 8.0GB total



100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.45it/s]Saving model checkpoint to 
runs/20260111_064045_89cu/test-model-reward/checkpoint-10
Configuration saved in runs/20260111_064045_89cu/test-model-reward/checkpoint-10/config.json
Model weights saved in runs/20260111_064045_89cu/test-model-reward/checkpoint-10/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-reward/checkpoint-10/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-reward/checkpoint-10/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-reward/checkpoint-10/special_tokens_map.json
{'loss': 0.6342, 'grad_norm': 62.14098358154297, 'learning_rate': 1e-05, 'num_tokens': 10501.0, 'min_reward': 
-2.1438491344451904, 'mean_reward': -2.083007574081421, 'max_reward': -2.0221660137176514, 'accuracy': 1.0, 'margin': 
0.12168312072753906, 'epoch': 1.11}
    âœ“ Checkpoint saved at step 10
  âœ“ Checkpoint saved at step 10 â†’ runs/20260111_064045_89cu/test-model-reward


Training completed. Do not forget to share your model on huggingface.co/models =)


    Step 10: loss: 0.8919 | epoch: 1.11 | GPU: 1.5/8.0GB
  Step 10/10 (100.0%)
  GPU 0: 1.54GB allocated / 5.09GB reserved / 8.0GB total



100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.45it/s]{'train_runtime': 15.2287, 'train_samples_per_second': 0.657, 
'train_steps_per_second': 0.657, 'train_loss': 0.8919261574745179, 'epoch': 1.11}
  Reward â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 10/10 | 0:00:09 < 0:00:00


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Reward Training Complete 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Total Steps:   10
 Total Epochs:  1.11
 Duration:      15.2s
 Steps/sec:     0.66
 Final Loss:    0.8919


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Reward Training Complete!                                                                                             
â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Total steps: 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
  Average step time: 0.366s
  Total steps: 10
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Training   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00                                                      
â”‚
â”‚ â ‹ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Step 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚
â”‚   â”‚ 
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚ â”‚
â”‚   â”‚ â”‚  Metric                                Value                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_runtime                        15.229                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_samples_per_second              0.657                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_steps_per_second                0.657                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  total_flos                7237592372736.000                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_loss                            0.892                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  epoch                                 1.111                                                                    
â”‚ â”‚ â”‚
â”‚   â”‚ 
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚ â”‚
â”‚   
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.51s/it]

Saving Reward model to: runs/20260111_064045_89cu/test-model-reward
Saving model checkpoint to runs/20260111_064045_89cu/test-model-reward
Configuration saved in runs/20260111_064045_89cu/test-model-reward/config.json
Model weights saved in runs/20260111_064045_89cu/test-model-reward/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-reward/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-reward/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-reward/special_tokens_map.json

âœ“ Reward model saved to runs/20260111_064045_89cu/test-model-reward
âœ“ REWARD completed in 22.7s
 âœ“ REWARD Training
     Completed
â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ Metric   â”ƒ Value â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ Duration â”‚ 22.7s â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜



â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DPO Training 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â„¹ Model: HuggingFaceTB/SmolLM2-135M-Instruct
â„¹ Dataset: trl-lib/ultrafeedback_binarized
â„¹ Output: runs/20260111_064045_89cu/test-model-dpo
â„¹ Output directory ready: runs/20260111_064045_89cu/test-model-dpo
[06:41:43] INFO     Starting DPO training with model=HuggingFaceTB/SmolLM2-135M-Instruct                                
dpo.py:45
â„¹ Loading model: HuggingFaceTB/SmolLM2-135M-Instruct

                      Model Information
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Property             â”ƒ Value                               â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Model Name           â”‚ HuggingFaceTB/SmolLM2-135M-Instruct â”‚
â”‚ Architecture         â”‚ LlamaForCausalLM                    â”‚
â”‚ Hidden Size          â”‚ 576                                 â”‚
â”‚ Layers               â”‚ 30                                  â”‚
â”‚ Attention Heads      â”‚ 9                                   â”‚
â”‚ Vocab Size           â”‚ 49,152                              â”‚
â”‚ Total Parameters     â”‚ 134,515,008                         â”‚
â”‚ Trainable Parameters â”‚ 134,515,008                         â”‚
â”‚ Trainable %          â”‚ 100.00%                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Loading dataset: trl-lib/ultrafeedback_binarized (split: train)

â„¹ Limited dataset from 62,135 to 10 samples
                      Dataset Information
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Property    â”ƒ Value                                          â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Dataset     â”‚ trl-lib/ultrafeedback_binarized                â”‚
â”‚ Samples     â”‚ 10                                             â”‚
â”‚ Columns     â”‚ chosen, rejected, score_chosen, score_rejected â”‚
â”‚ Sample Keys â”‚ chosen, rejected, score_chosen                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â„¹ Creating DPO trainer...
max_steps is given, it will override any value given in num_train_epochs
Starting DPO training loop...
The following columns in the Training set don't have a corresponding argument in `LlamaForCausalLM.forward` and have 
been ignored: prompt, score_chosen, score_rejected. If prompt, score_chosen, score_rejected are not expected by 
`LlamaForCausalLM.forward`,  you can safely ignore this message.
***** Running training *****
  Num examples = 10
  Num Epochs = 1
  Instantaneous batch size per device = 1
  Total train batch size (w. parallel, distributed & accumulation) = 1
  Gradient Accumulation steps = 1
  Total optimization steps = 10
  Number of trainable parameters = 134,515,008
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DPO Training Started 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

 Max Steps:        10
 Batch Size:       1
 Gradient Accum:   1
 Effective Batch:  1
 Learning Rate:    1.00e-06
 Warmup Steps:     0
 Save Strategy:    SaveStrategy.STEPS (every 5)


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ DPO Training Initialized                                                                                              
â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Max steps: 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Training Arguments 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

                                                                                   TrainingArguments
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                               â”ƒ Value                                                                       
â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ output_dir                              â”‚ runs/20260111_064045_89cu/test-model-dpo                                    
â”‚
â”‚ overwrite_output_dir                    â”‚ No                                                                          
â”‚
â”‚ do_train                                â”‚ No                                                                          
â”‚
â”‚ do_eval                                 â”‚ No                                                                          
â”‚
â”‚ do_predict                              â”‚ No                                                                          
â”‚
â”‚ eval_strategy                           â”‚ IntervalStrategy.NO                                                         
â”‚
â”‚ prediction_loss_only                    â”‚ No                                                                          
â”‚
â”‚ per_device_train_batch_size             â”‚ 1                                                                           
â”‚
â”‚ per_device_eval_batch_size              â”‚ 8                                                                           
â”‚
â”‚ per_gpu_train_batch_size                â”‚ None                                                                        
â”‚
â”‚ per_gpu_eval_batch_size                 â”‚ None                                                                        
â”‚
â”‚ gradient_accumulation_steps             â”‚ 1                                                                           
â”‚
â”‚ eval_accumulation_steps                 â”‚ None                                                                        
â”‚
â”‚ eval_delay                              â”‚ 0                                                                           
â”‚
â”‚ torch_empty_cache_steps                 â”‚ None                                                                        
â”‚
â”‚ learning_rate                           â”‚ 1e-06                                                                       
â”‚
â”‚ weight_decay                            â”‚ 0.0                                                                         
â”‚
â”‚ adam_beta1                              â”‚ 0.9                                                                         
â”‚
â”‚ adam_beta2                              â”‚ 0.999                                                                       
â”‚
â”‚ adam_epsilon                            â”‚ 1e-08                                                                       
â”‚
â”‚ max_grad_norm                           â”‚ 1.0                                                                         
â”‚
â”‚ num_train_epochs                        â”‚ 3.0                                                                         
â”‚
â”‚ max_steps                               â”‚ 10                                                                          
â”‚
â”‚ lr_scheduler_type                       â”‚ SchedulerType.LINEAR                                                        
â”‚
â”‚ lr_scheduler_kwargs                     â”‚ None                                                                        
â”‚
â”‚ warmup_ratio                            â”‚ 0.0                                                                         
â”‚
â”‚ warmup_steps                            â”‚ 0                                                                           
â”‚
â”‚ log_level                               â”‚ info                                                                        
â”‚
â”‚ log_level_replica                       â”‚ warning                                                                     
â”‚
â”‚ log_on_each_node                        â”‚ Yes                                                                         
â”‚
â”‚ logging_dir                             â”‚ runs/20260111_064045_89cu/test-model-dpo/logs                               
â”‚
â”‚ logging_strategy                        â”‚ IntervalStrategy.STEPS                                                      
â”‚
â”‚ logging_first_step                      â”‚ No                                                                          
â”‚
â”‚ logging_steps                           â”‚ 1                                                                           
â”‚
â”‚ logging_nan_inf_filter                  â”‚ Yes                                                                         
â”‚
â”‚ save_strategy                           â”‚ SaveStrategy.STEPS                                                          
â”‚
â”‚ save_steps                              â”‚ 5                                                                           
â”‚
â”‚ save_total_limit                        â”‚ 2                                                                           
â”‚
â”‚ save_safetensors                        â”‚ Yes                                                                         
â”‚
â”‚ save_on_each_node                       â”‚ No                                                                          
â”‚
â”‚ save_only_model                         â”‚ No                                                                          
â”‚
â”‚ restore_callback_states_from_checkpoint â”‚ No                                                                          
â”‚
â”‚ no_cuda                                 â”‚ No                                                                          
â”‚
â”‚ use_cpu                                 â”‚ No                                                                          
â”‚
â”‚ use_mps_device                          â”‚ No                                                                          
â”‚
â”‚ seed                                    â”‚ 42                                                                          
â”‚
â”‚ data_seed                               â”‚ None                                                                        
â”‚
â”‚ jit_mode_eval                           â”‚ No                                                                          
â”‚
â”‚ bf16                                    â”‚ No                                                                          
â”‚
â”‚ fp16                                    â”‚ No                                                                          
â”‚
â”‚ fp16_opt_level                          â”‚ O1                                                                          
â”‚
â”‚ half_precision_backend                  â”‚ auto                                                                        
â”‚
â”‚ bf16_full_eval                          â”‚ No                                                                          
â”‚
â”‚ fp16_full_eval                          â”‚ No                                                                          
â”‚
â”‚ tf32                                    â”‚ None                                                                        
â”‚
â”‚ local_rank                              â”‚ 0                                                                           
â”‚
â”‚ ddp_backend                             â”‚ None                                                                        
â”‚
â”‚ tpu_num_cores                           â”‚ None                                                                        
â”‚
â”‚ tpu_metrics_debug                       â”‚ No                                                                          
â”‚
â”‚ debug                                   â”‚                                                                             
â”‚
â”‚ dataloader_drop_last                    â”‚ No                                                                          
â”‚
â”‚ eval_steps                              â”‚ None                                                                        
â”‚
â”‚ dataloader_num_workers                  â”‚ 0                                                                           
â”‚
â”‚ dataloader_prefetch_factor              â”‚ None                                                                        
â”‚
â”‚ past_index                              â”‚ -1                                                                          
â”‚
â”‚ run_name                                â”‚ None                                                                        
â”‚
â”‚ disable_tqdm                            â”‚ No                                                                          
â”‚
â”‚ remove_unused_columns                   â”‚ Yes                                                                         
â”‚
â”‚ label_names                             â”‚ None                                                                        
â”‚
â”‚ load_best_model_at_end                  â”‚ No                                                                          
â”‚
â”‚ metric_for_best_model                   â”‚ None                                                                        
â”‚
â”‚ greater_is_better                       â”‚ None                                                                        
â”‚
â”‚ ignore_data_skip                        â”‚ No                                                                          
â”‚
â”‚ fsdp                                    â”‚                                                                             
â”‚
â”‚ fsdp_min_num_params                     â”‚ 0                                                                           
â”‚
â”‚ fsdp_config                             â”‚ {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 
'xla_fsdp_grad_ckpt': False}                                                    â”‚
â”‚ fsdp_transformer_layer_cls_to_wrap      â”‚ None                                                                        
â”‚
â”‚ accelerator_config                      â”‚ AcceleratorConfig(split_batches=False, dispatch_batches=None, 
even_batches=True, use_seedable_sampler=True, non_blocking=False,           â”‚
â”‚                                         â”‚ gradient_accumulation_kwargs=None, use_configured_state=False)              
â”‚
â”‚ parallelism_config                      â”‚ None                                                                        
â”‚
â”‚ deepspeed                               â”‚ None                                                                        
â”‚
â”‚ label_smoothing_factor                  â”‚ 0.0                                                                         
â”‚
â”‚ optim                                   â”‚ OptimizerNames.ADAMW_TORCH_FUSED                                            
â”‚
â”‚ optim_args                              â”‚ None                                                                        
â”‚
â”‚ adafactor                               â”‚ No                                                                          
â”‚
â”‚ group_by_length                         â”‚ No                                                                          
â”‚
â”‚ length_column_name                      â”‚ length                                                                      
â”‚
â”‚ report_to                               â”‚ wandb                                                                       
â”‚
â”‚ project                                 â”‚ huggingface                                                                 
â”‚
â”‚ trackio_space_id                        â”‚ trackio                                                                     
â”‚
â”‚ ddp_find_unused_parameters              â”‚ None                                                                        
â”‚
â”‚ ddp_bucket_cap_mb                       â”‚ None                                                                        
â”‚
â”‚ ddp_broadcast_buffers                   â”‚ None                                                                        
â”‚
â”‚ dataloader_pin_memory                   â”‚ No                                                                          
â”‚
â”‚ dataloader_persistent_workers           â”‚ No                                                                          
â”‚
â”‚ skip_memory_metrics                     â”‚ Yes                                                                         
â”‚
â”‚ use_legacy_prediction_loop              â”‚ No                                                                          
â”‚
â”‚ push_to_hub                             â”‚ No                                                                          
â”‚
â”‚ resume_from_checkpoint                  â”‚ None                                                                        
â”‚
â”‚ hub_model_id                            â”‚ None                                                                        
â”‚
â”‚ hub_strategy                            â”‚ HubStrategy.EVERY_SAVE                                                      
â”‚
â”‚ hub_token                               â”‚ None                                                                        
â”‚
â”‚ hub_private_repo                        â”‚ None                                                                        
â”‚
â”‚ hub_always_push                         â”‚ No                                                                          
â”‚
â”‚ hub_revision                            â”‚ None                                                                        
â”‚
â”‚ gradient_checkpointing                  â”‚ No                                                                          
â”‚
â”‚ gradient_checkpointing_kwargs           â”‚ None                                                                        
â”‚
â”‚ include_inputs_for_metrics              â”‚ No                                                                          
â”‚
â”‚ include_for_metrics                     â”‚                                                                             
â”‚
â”‚ eval_do_concat_batches                  â”‚ Yes                                                                         
â”‚
â”‚ fp16_backend                            â”‚ auto                                                                        
â”‚
â”‚ push_to_hub_model_id                    â”‚ None                                                                        
â”‚
â”‚ push_to_hub_organization                â”‚ None                                                                        
â”‚
â”‚ push_to_hub_token                       â”‚ None                                                                        
â”‚
â”‚ mp_parameters                           â”‚                                                                             
â”‚
â”‚ auto_find_batch_size                    â”‚ No                                                                          
â”‚
â”‚ full_determinism                        â”‚ No                                                                          
â”‚
â”‚ torchdynamo                             â”‚ None                                                                        
â”‚
â”‚ ray_scope                               â”‚ last                                                                        
â”‚
â”‚ ddp_timeout                             â”‚ 1800                                                                        
â”‚
â”‚ torch_compile                           â”‚ No                                                                          
â”‚
â”‚ torch_compile_backend                   â”‚ None                                                                        
â”‚
â”‚ torch_compile_mode                      â”‚ None                                                                        
â”‚
â”‚ include_tokens_per_second               â”‚ No                                                                          
â”‚
â”‚ include_num_input_tokens_seen           â”‚ no                                                                          
â”‚
â”‚ neftune_noise_alpha                     â”‚ None                                                                        
â”‚
â”‚ optim_target_modules                    â”‚ None                                                                        
â”‚
â”‚ batch_eval_metrics                      â”‚ No                                                                          
â”‚
â”‚ eval_on_start                           â”‚ No                                                                          
â”‚
â”‚ use_liger_kernel                        â”‚ No                                                                          
â”‚
â”‚ liger_kernel_config                     â”‚ None                                                                        
â”‚
â”‚ eval_use_gather_object                  â”‚ No                                                                          
â”‚
â”‚ average_tokens_across_devices           â”‚ Yes                                                                         
â”‚
â”‚ model_init_kwargs                       â”‚ None                                                                        
â”‚
â”‚ ref_model_init_kwargs                   â”‚ None                                                                        
â”‚
â”‚ model_adapter_name                      â”‚ None                                                                        
â”‚
â”‚ ref_adapter_name                        â”‚ None                                                                        
â”‚
â”‚ force_use_ref_model                     â”‚ No                                                                          
â”‚
â”‚ disable_dropout                         â”‚ Yes                                                                         
â”‚
â”‚ use_logits_to_keep                      â”‚ No                                                                          
â”‚
â”‚ dataset_num_proc                        â”‚ None                                                                        
â”‚
â”‚ pad_token                               â”‚ None                                                                        
â”‚
â”‚ label_pad_token_id                      â”‚ -100                                                                        
â”‚
â”‚ max_prompt_length                       â”‚ 512                                                                         
â”‚
â”‚ max_completion_length                   â”‚ None                                                                        
â”‚
â”‚ max_length                              â”‚ 1024                                                                        
â”‚
â”‚ truncation_mode                         â”‚ keep_end                                                                    
â”‚
â”‚ padding_free                            â”‚ No                                                                          
â”‚
â”‚ precompute_ref_log_probs                â”‚ No                                                                          
â”‚
â”‚ precompute_ref_batch_size               â”‚ None                                                                        
â”‚
â”‚ tools                                   â”‚ None                                                                        
â”‚
â”‚ loss_type                               â”‚ sigmoid                                                                     
â”‚
â”‚ use_liger_loss                          â”‚ None                                                                        
â”‚
â”‚ base_model_attribute_name               â”‚ model                                                                       
â”‚
â”‚ beta                                    â”‚ 0.1                                                                         
â”‚
â”‚ f_divergence_type                       â”‚ FDivergenceType.REVERSE_KL                                                  
â”‚
â”‚ f_alpha_divergence_coef                 â”‚ 1.0                                                                         
â”‚
â”‚ reference_free                          â”‚ No                                                                          
â”‚
â”‚ label_smoothing                         â”‚ 0.0                                                                         
â”‚
â”‚ use_weighting                           â”‚ No                                                                          
â”‚
â”‚ rpo_alpha                               â”‚ None                                                                        
â”‚
â”‚ ld_alpha                                â”‚ None                                                                        
â”‚
â”‚ discopop_tau                            â”‚ 0.05                                                                        
â”‚
â”‚ loss_weights                            â”‚ None                                                                        
â”‚
â”‚ sync_ref_model                          â”‚ No                                                                          
â”‚
â”‚ ref_model_mixup_alpha                   â”‚ 0.6                                                                         
â”‚
â”‚ ref_model_sync_steps                    â”‚ 512                                                                         
â”‚
â”‚ generate_during_eval                    â”‚ No                                                                          
â”‚
â”‚ distributed_state                       â”‚ Distributed environment: DistributedType.NO                                 
â”‚
â”‚                                         â”‚ Num processes: 1                                                            
â”‚
â”‚                                         â”‚ Process index: 0                                                            
â”‚
â”‚                                         â”‚ Local process index: 0                                                      
â”‚
â”‚                                         â”‚ Device: cuda                                                                
â”‚
â”‚                                         â”‚                                                                             
â”‚
â”‚ deepspeed_plugin                        â”‚ None                                                                        
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


  0%|          | 0/10 [00:00<?, ?it/s]
 10%|â–ˆ         | 1/10 [00:00<00:06,  1.45it/s]    Step 1: loss: 0.6931 | lr: 1.00e-06 | grad: 51.93 | epoch: 0.10 | GPU:
2.1/8.0GB
  Step 1/10 (10.0%) loss=0.6931 | lr=1.00e-06 | grad=51.932
  GPU 0: 2.07GB allocated / 3.74GB reserved / 8.0GB total



 10%|â–ˆ         | 1/10 [00:00<00:06,  1.45it/s]
 20%|â–ˆâ–ˆ        | 2/10 [00:01<00:04,  1.71it/s]{'loss': 0.6931, 'grad_norm': 51.93205642700195, 'learning_rate': 1e-06, 
'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': 
-23.095151901245117, 'logps/rejected': -286.7440185546875, 'logits/chosen': 9.633723258972168, 'logits/rejected': 
8.877617835998535, 'epoch': 0.1}
  Step 2/10 (20.0%) loss=0.6870 | lr=9.00e-07 | grad=86.542
  GPU 0: 2.07GB allocated / 5.53GB reserved / 8.0GB total



 20%|â–ˆâ–ˆ        | 2/10 [00:01<00:04,  1.71it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:01<00:03,  2.15it/s]{'loss': 0.687, 'grad_norm': 86.54212188720703, 'learning_rate': 9e-07, 
'rewards/chosen': -0.0018249511485919356, 'rewards/rejected': -0.01416015625, 'rewards/accuracies': 1.0, 
'rewards/margins': 0.01233520545065403, 'logps/chosen': -124.83000183105469, 'logps/rejected': -367.3089904785156, 
'logits/chosen': 4.862440586090088, 'logits/rejected': 4.466541290283203, 'epoch': 0.2}
  Step 3/10 (30.0%) loss=0.6801 | lr=8.00e-07 | grad=46.476
  GPU 0: 2.07GB allocated / 5.54GB reserved / 8.0GB total



 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:01<00:03,  2.15it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:01<00:02,  2.15it/s]{'loss': 0.6801, 'grad_norm': 46.47560119628906, 'learning_rate': 8e-07, 
'rewards/chosen': 0.0010726929176598787, 'rewards/rejected': -0.02529144287109375, 'rewards/accuracies': 1.0, 
'rewards/margins': 0.02636413648724556, 'logps/chosen': -122.35832977294922, 'logps/rejected': -90.44725036621094, 
'logits/chosen': 4.978423595428467, 'logits/rejected': 5.768970489501953, 'epoch': 0.3}
  Step 4/10 (40.0%) loss=0.6929 | lr=7.00e-07 | grad=49.100
  GPU 0: 2.07GB allocated / 5.83GB reserved / 8.0GB total



 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:02<00:02,  2.15it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:43<01:16, 15.38s/it]{'loss': 0.6929, 'grad_norm': 49.100467681884766, 'learning_rate': 7e-07, 
'rewards/chosen': 0.0012451171642169356, 'rewards/rejected': 0.0008190154912881553, 'rewards/accuracies': 1.0, 
'rewards/margins': 0.0004261016729287803, 'logps/chosen': -253.89620971679688, 'logps/rejected': -38.87993621826172, 
'logits/chosen': 2.8963303565979004, 'logits/rejected': 5.590914726257324, 'epoch': 0.4}
    Step 5: loss: 0.6891 | lr: 6.00e-07 | grad: 165.90 | epoch: 0.50 | GPU: 2.1/8.0GB
  Step 5/10 (50.0%) loss=0.6891 | lr=6.00e-07 | grad=165.897
  GPU 0: 2.07GB allocated / 9.20GB reserved / 8.0GB total



 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:43<01:16, 15.38s/it]Saving model checkpoint to 
runs/20260111_064045_89cu/test-model-dpo/checkpoint-5
Configuration saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-5/config.json
Configuration saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-5/generation_config.json
Model weights saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-5/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-5/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-5/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-5/special_tokens_map.json
{'loss': 0.6891, 'grad_norm': 165.89675903320312, 'learning_rate': 6e-07, 'rewards/chosen': 0.0002685546933207661, 
'rewards/rejected': -0.007781982421875, 'rewards/accuracies': 1.0, 'rewards/margins': 0.00805053673684597, 
'logps/chosen': -1142.656494140625, 'logps/rejected': -846.96875, 'logits/chosen': 2.909712553024292, 'logits/rejected':
-0.39845365285873413, 'epoch': 0.5}
    âœ“ Checkpoint saved at step 5
  âœ“ Checkpoint saved at step 5 â†’ runs/20260111_064045_89cu/test-model-dpo

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:52<00:52, 13.22s/it]    Step 6: loss: 0.6922 | lr: 5.00e-07 | grad: 28.86 | epoch: 0.60 | GPU:
2.1/8.0GB
  Step 6/10 (60.0%) loss=0.6922 | lr=5.00e-07 | grad=28.859
  GPU 0: 2.07GB allocated / 9.20GB reserved / 8.0GB total



 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:52<00:52, 13.22s/it]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:08<00:42, 14.04s/it]{'loss': 0.6922, 'grad_norm': 28.858951568603516, 'learning_rate': 5e-07, 
'rewards/chosen': -0.0011108398903161287, 'rewards/rejected': -0.002989196917042136, 'rewards/accuracies': 1.0, 
'rewards/margins': 0.0018783570267260075, 'logps/chosen': -67.00868225097656, 'logps/rejected': -55.777503967285156, 
'logits/chosen': 1.497898817062378, 'logits/rejected': 2.8278889656066895, 'epoch': 0.6}
    Step 7: loss: 0.6940 | lr: 4.00e-07 | grad: 125.96 | epoch: 0.70 | GPU: 2.1/8.0GB
  Step 7/10 (70.0%) loss=0.6940 | lr=4.00e-07 | grad=125.962
  GPU 0: 2.07GB allocated / 9.20GB reserved / 8.0GB total



 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:08<00:42, 14.04s/it]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:09<00:19,  9.90s/it]{'loss': 0.694, 'grad_norm': 125.96175384521484, 'learning_rate': 4e-07, 
'rewards/chosen': -0.0072265625931322575, 'rewards/rejected': -0.005541992373764515, 'rewards/accuracies': 0.0, 
'rewards/margins': -0.0016845702193677425, 'logps/chosen': -806.9296875, 'logps/rejected': -625.1651611328125, 
'logits/chosen': 2.697431802749634, 'logits/rejected': 6.991037368774414, 'epoch': 0.7}
  Step 8/10 (80.0%) loss=0.6879 | lr=3.00e-07 | grad=129.227
  GPU 0: 2.07GB allocated / 9.20GB reserved / 8.0GB total



 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:09<00:19,  9.90s/it]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:18<00:09,  9.55s/it]{'loss': 0.6879, 'grad_norm': 129.22747802734375, 'learning_rate': 3e-07, 
'rewards/chosen': 0.0042968750931322575, 'rewards/rejected': -0.006213379092514515, 'rewards/accuracies': 1.0, 
'rewards/margins': 0.01051025465130806, 'logps/chosen': -1561.5487060546875, 'logps/rejected': -993.500732421875, 
'logits/chosen': 2.944039821624756, 'logits/rejected': 0.10538387298583984, 'epoch': 0.8}
    Step 9: loss: 0.6918 | lr: 2.00e-07 | grad: 119.98 | epoch: 0.90 | GPU: 2.1/8.0GB
  Step 9/10 (90.0%) loss=0.6918 | lr=2.00e-07 | grad=119.983
  GPU 0: 2.07GB allocated / 9.20GB reserved / 8.0GB total



 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:18<00:09,  9.55s/it]{'loss': 0.6918, 'grad_norm': 119.98326873779297, 'learning_rate': 2e-07, 
'rewards/chosen': -0.0019775391556322575, 'rewards/rejected': -0.0046630860306322575, 'rewards/accuracies': 1.0, 
'rewards/margins': 0.002685546875, 'logps/chosen': -1061.828857421875, 'logps/rejected': -1175.4130859375, 
'logits/chosen': 2.953946590423584, 'logits/rejected': 2.8456578254699707, 'epoch': 0.9}
  Step 10 | 0.834s/step | avg: 7.311s | ETA: 0.0s

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:19<00:00,  6.87s/it]  Step 10/10 (100.0%) loss=0.6889 | lr=1.00e-07 | grad=32.738
  GPU 0: 2.07GB allocated / 9.20GB reserved / 8.0GB total



100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:19<00:00,  6.87s/it]Saving model checkpoint to 
runs/20260111_064045_89cu/test-model-dpo/checkpoint-10
Configuration saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-10/config.json
Configuration saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-10/generation_config.json
Model weights saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-10/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-10/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-10/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-dpo/checkpoint-10/special_tokens_map.json
{'loss': 0.6889, 'grad_norm': 32.73799133300781, 'learning_rate': 1e-07, 'rewards/chosen': -0.00033969880314543843, 
'rewards/rejected': -0.008920288644731045, 'rewards/accuracies': 1.0, 'rewards/margins': 0.008580589666962624, 
'logps/chosen': -8.463298797607422, 'logps/rejected': -139.4349822998047, 'logits/chosen': 9.670549392700195, 
'logits/rejected': 2.256880044937134, 'epoch': 1.0}
    âœ“ Checkpoint saved at step 10
  âœ“ Checkpoint saved at step 10 â†’ runs/20260111_064045_89cu/test-model-dpo


Training completed. Do not forget to share your model on huggingface.co/models =)


    Step 10: loss: 0.6897 | epoch: 1.00 | GPU: 2.1/8.0GB
  Step 10/10 (100.0%)
  GPU 0: 2.07GB allocated / 9.20GB reserved / 8.0GB total



100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:26<00:00,  6.87s/it]{'train_runtime': 86.2242, 'train_samples_per_second': 0.116, 
'train_steps_per_second': 0.116, 'train_loss': 0.6897037208080292, 'epoch': 1.0}
  DPO â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 10/10 | 0:01:17 < 0:00:00


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DPO Training Complete 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Total Steps:   10
 Total Epochs:  1.00
 Duration:      1m 26.2s
 Steps/sec:     0.12
 Final Loss:    0.6897


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ DPO Training Complete!                                                                                                
â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Total steps: 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
  Average step time: 7.311s
  Total steps: 10
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Training   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00                                                      
â”‚
â”‚ â ‹ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Step 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚
â”‚   â”‚ 
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚ â”‚
â”‚   â”‚ â”‚  Metric                     Value                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_runtime             86.224                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_samples_per_second   0.116                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_steps_per_second     0.116                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  total_flos                 0.000                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_loss                 0.690                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  epoch                      1.000                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ 
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚ â”‚
â”‚   
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:26<00:00,  8.61s/it]

Saving DPO model to: runs/20260111_064045_89cu/test-model-dpo
Saving model checkpoint to runs/20260111_064045_89cu/test-model-dpo
Configuration saved in runs/20260111_064045_89cu/test-model-dpo/config.json
Configuration saved in runs/20260111_064045_89cu/test-model-dpo/generation_config.json
Model weights saved in runs/20260111_064045_89cu/test-model-dpo/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-dpo/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-dpo/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-dpo/special_tokens_map.json

âœ“ DPO model saved to runs/20260111_064045_89cu/test-model-dpo
âœ“ DPO completed in 1m 33.5s
    âœ“ DPO Training
       Completed
â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Metric   â”ƒ Value    â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Duration â”‚ 1m 33.5s â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GRPO Training 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â„¹ Model: HuggingFaceTB/SmolLM2-135M-Instruct
â„¹ Dataset: trl-lib/DeepMath-103K
â„¹ Output: runs/20260111_064045_89cu/test-model-grpo
â„¹ Output directory ready: runs/20260111_064045_89cu/test-model-grpo
[06:43:17] INFO     Starting GRPO training with model=HuggingFaceTB/SmolLM2-135M-Instruct                               
grpo.py:65
        GRPO Extra Config
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ Parameter             â”ƒ Value â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ reward_func           â”‚ None  â”‚
â”‚ num_generations       â”‚ 2     â”‚
â”‚ max_completion_length â”‚ 32    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜

â„¹ Loading test model: HuggingFaceTB/SmolLM2-135M-Instruct

                      Model Information
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Property             â”ƒ Value                               â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Model Name           â”‚ HuggingFaceTB/SmolLM2-135M-Instruct â”‚
â”‚ Architecture         â”‚ LlamaForCausalLM                    â”‚
â”‚ Hidden Size          â”‚ 576                                 â”‚
â”‚ Layers               â”‚ 30                                  â”‚
â”‚ Attention Heads      â”‚ 9                                   â”‚
â”‚ Vocab Size           â”‚ 49,152                              â”‚
â”‚ Total Parameters     â”‚ 134,515,008                         â”‚
â”‚ Trainable Parameters â”‚ 134,515,008                         â”‚
â”‚ Trainable %          â”‚ 100.00%                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Loading dataset: trl-lib/DeepMath-103K (split: train)

â„¹ Limited dataset from 97,870 to 10 samples
          Dataset Information
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Property    â”ƒ Value                 â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Dataset     â”‚ trl-lib/DeepMath-103K â”‚
â”‚ Samples     â”‚ 10                    â”‚
â”‚ Columns     â”‚ prompt, solution      â”‚
â”‚ Sample Keys â”‚ prompt, solution      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â„¹ Using test reward function (length-based)
â„¹ Adjusting per_device_train_batch_size from 1 to 2 (must be divisible by num_generations=2)
â„¹ Creating GRPO trainer...
  num_generations: 2
  max_completion_length: 32
max_steps is given, it will override any value given in num_train_epochs
Starting GRPO training loop...
Note: GRPO generates multiple completions per sample, which may take longer.
***** Running training *****
  Num examples = 10
  Num Epochs = 1
  Instantaneous batch size per device = 2
  Total train batch size (w. parallel, distributed & accumulation) = 2
  Gradient Accumulation steps = 1
  Total optimization steps = 10
  Number of trainable parameters = 134,515,008
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GRPO Training Started 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

 Max Steps:        10
 Batch Size:       2
 Gradient Accum:   1
 Effective Batch:  2
 Learning Rate:    1.00e-06
 Warmup Steps:     0
 Save Strategy:    SaveStrategy.STEPS (every 5)


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ GRPO Training Initialized                                                                                             
â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Max steps: 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Training Arguments 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

                                                                                   TrainingArguments
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                               â”ƒ Value                                                                       
â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ output_dir                              â”‚ runs/20260111_064045_89cu/test-model-grpo                                   
â”‚
â”‚ overwrite_output_dir                    â”‚ No                                                                          
â”‚
â”‚ do_train                                â”‚ No                                                                          
â”‚
â”‚ do_eval                                 â”‚ No                                                                          
â”‚
â”‚ do_predict                              â”‚ No                                                                          
â”‚
â”‚ eval_strategy                           â”‚ IntervalStrategy.NO                                                         
â”‚
â”‚ prediction_loss_only                    â”‚ No                                                                          
â”‚
â”‚ per_device_train_batch_size             â”‚ 2                                                                           
â”‚
â”‚ per_device_eval_batch_size              â”‚ 8                                                                           
â”‚
â”‚ per_gpu_train_batch_size                â”‚ None                                                                        
â”‚
â”‚ per_gpu_eval_batch_size                 â”‚ None                                                                        
â”‚
â”‚ gradient_accumulation_steps             â”‚ 1                                                                           
â”‚
â”‚ eval_accumulation_steps                 â”‚ None                                                                        
â”‚
â”‚ eval_delay                              â”‚ 0                                                                           
â”‚
â”‚ torch_empty_cache_steps                 â”‚ None                                                                        
â”‚
â”‚ learning_rate                           â”‚ 1e-06                                                                       
â”‚
â”‚ weight_decay                            â”‚ 0.0                                                                         
â”‚
â”‚ adam_beta1                              â”‚ 0.9                                                                         
â”‚
â”‚ adam_beta2                              â”‚ 0.999                                                                       
â”‚
â”‚ adam_epsilon                            â”‚ 1e-08                                                                       
â”‚
â”‚ max_grad_norm                           â”‚ 1.0                                                                         
â”‚
â”‚ num_train_epochs                        â”‚ 3.0                                                                         
â”‚
â”‚ max_steps                               â”‚ 10                                                                          
â”‚
â”‚ lr_scheduler_type                       â”‚ SchedulerType.LINEAR                                                        
â”‚
â”‚ lr_scheduler_kwargs                     â”‚ None                                                                        
â”‚
â”‚ warmup_ratio                            â”‚ 0.0                                                                         
â”‚
â”‚ warmup_steps                            â”‚ 0                                                                           
â”‚
â”‚ log_level                               â”‚ info                                                                        
â”‚
â”‚ log_level_replica                       â”‚ warning                                                                     
â”‚
â”‚ log_on_each_node                        â”‚ Yes                                                                         
â”‚
â”‚ logging_dir                             â”‚ runs/20260111_064045_89cu/test-model-grpo/logs                              
â”‚
â”‚ logging_strategy                        â”‚ IntervalStrategy.STEPS                                                      
â”‚
â”‚ logging_first_step                      â”‚ No                                                                          
â”‚
â”‚ logging_steps                           â”‚ 1                                                                           
â”‚
â”‚ logging_nan_inf_filter                  â”‚ Yes                                                                         
â”‚
â”‚ save_strategy                           â”‚ SaveStrategy.STEPS                                                          
â”‚
â”‚ save_steps                              â”‚ 5                                                                           
â”‚
â”‚ save_total_limit                        â”‚ 2                                                                           
â”‚
â”‚ save_safetensors                        â”‚ Yes                                                                         
â”‚
â”‚ save_on_each_node                       â”‚ No                                                                          
â”‚
â”‚ save_only_model                         â”‚ No                                                                          
â”‚
â”‚ restore_callback_states_from_checkpoint â”‚ No                                                                          
â”‚
â”‚ no_cuda                                 â”‚ No                                                                          
â”‚
â”‚ use_cpu                                 â”‚ No                                                                          
â”‚
â”‚ use_mps_device                          â”‚ No                                                                          
â”‚
â”‚ seed                                    â”‚ 42                                                                          
â”‚
â”‚ data_seed                               â”‚ None                                                                        
â”‚
â”‚ jit_mode_eval                           â”‚ No                                                                          
â”‚
â”‚ bf16                                    â”‚ No                                                                          
â”‚
â”‚ fp16                                    â”‚ No                                                                          
â”‚
â”‚ fp16_opt_level                          â”‚ O1                                                                          
â”‚
â”‚ half_precision_backend                  â”‚ auto                                                                        
â”‚
â”‚ bf16_full_eval                          â”‚ No                                                                          
â”‚
â”‚ fp16_full_eval                          â”‚ No                                                                          
â”‚
â”‚ tf32                                    â”‚ None                                                                        
â”‚
â”‚ local_rank                              â”‚ 0                                                                           
â”‚
â”‚ ddp_backend                             â”‚ None                                                                        
â”‚
â”‚ tpu_num_cores                           â”‚ None                                                                        
â”‚
â”‚ tpu_metrics_debug                       â”‚ No                                                                          
â”‚
â”‚ debug                                   â”‚                                                                             
â”‚
â”‚ dataloader_drop_last                    â”‚ No                                                                          
â”‚
â”‚ eval_steps                              â”‚ None                                                                        
â”‚
â”‚ dataloader_num_workers                  â”‚ 0                                                                           
â”‚
â”‚ dataloader_prefetch_factor              â”‚ None                                                                        
â”‚
â”‚ past_index                              â”‚ -1                                                                          
â”‚
â”‚ run_name                                â”‚ None                                                                        
â”‚
â”‚ disable_tqdm                            â”‚ No                                                                          
â”‚
â”‚ remove_unused_columns                   â”‚ No                                                                          
â”‚
â”‚ label_names                             â”‚ None                                                                        
â”‚
â”‚ load_best_model_at_end                  â”‚ No                                                                          
â”‚
â”‚ metric_for_best_model                   â”‚ None                                                                        
â”‚
â”‚ greater_is_better                       â”‚ None                                                                        
â”‚
â”‚ ignore_data_skip                        â”‚ No                                                                          
â”‚
â”‚ fsdp                                    â”‚                                                                             
â”‚
â”‚ fsdp_min_num_params                     â”‚ 0                                                                           
â”‚
â”‚ fsdp_config                             â”‚ {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 
'xla_fsdp_grad_ckpt': False}                                                    â”‚
â”‚ fsdp_transformer_layer_cls_to_wrap      â”‚ None                                                                        
â”‚
â”‚ accelerator_config                      â”‚ AcceleratorConfig(split_batches=False, dispatch_batches=None, 
even_batches=True, use_seedable_sampler=True, non_blocking=False,           â”‚
â”‚                                         â”‚ gradient_accumulation_kwargs=None, use_configured_state=False)              
â”‚
â”‚ parallelism_config                      â”‚ None                                                                        
â”‚
â”‚ deepspeed                               â”‚ None                                                                        
â”‚
â”‚ label_smoothing_factor                  â”‚ 0.0                                                                         
â”‚
â”‚ optim                                   â”‚ OptimizerNames.ADAMW_TORCH_FUSED                                            
â”‚
â”‚ optim_args                              â”‚ None                                                                        
â”‚
â”‚ adafactor                               â”‚ No                                                                          
â”‚
â”‚ group_by_length                         â”‚ No                                                                          
â”‚
â”‚ length_column_name                      â”‚ length                                                                      
â”‚
â”‚ report_to                               â”‚ wandb                                                                       
â”‚
â”‚ project                                 â”‚ huggingface                                                                 
â”‚
â”‚ trackio_space_id                        â”‚ trackio                                                                     
â”‚
â”‚ ddp_find_unused_parameters              â”‚ None                                                                        
â”‚
â”‚ ddp_bucket_cap_mb                       â”‚ None                                                                        
â”‚
â”‚ ddp_broadcast_buffers                   â”‚ None                                                                        
â”‚
â”‚ dataloader_pin_memory                   â”‚ No                                                                          
â”‚
â”‚ dataloader_persistent_workers           â”‚ No                                                                          
â”‚
â”‚ skip_memory_metrics                     â”‚ Yes                                                                         
â”‚
â”‚ use_legacy_prediction_loop              â”‚ No                                                                          
â”‚
â”‚ push_to_hub                             â”‚ No                                                                          
â”‚
â”‚ resume_from_checkpoint                  â”‚ None                                                                        
â”‚
â”‚ hub_model_id                            â”‚ None                                                                        
â”‚
â”‚ hub_strategy                            â”‚ HubStrategy.EVERY_SAVE                                                      
â”‚
â”‚ hub_token                               â”‚ None                                                                        
â”‚
â”‚ hub_private_repo                        â”‚ None                                                                        
â”‚
â”‚ hub_always_push                         â”‚ No                                                                          
â”‚
â”‚ hub_revision                            â”‚ None                                                                        
â”‚
â”‚ gradient_checkpointing                  â”‚ No                                                                          
â”‚
â”‚ gradient_checkpointing_kwargs           â”‚ None                                                                        
â”‚
â”‚ include_inputs_for_metrics              â”‚ No                                                                          
â”‚
â”‚ include_for_metrics                     â”‚                                                                             
â”‚
â”‚ eval_do_concat_batches                  â”‚ Yes                                                                         
â”‚
â”‚ fp16_backend                            â”‚ auto                                                                        
â”‚
â”‚ push_to_hub_model_id                    â”‚ None                                                                        
â”‚
â”‚ push_to_hub_organization                â”‚ None                                                                        
â”‚
â”‚ push_to_hub_token                       â”‚ None                                                                        
â”‚
â”‚ mp_parameters                           â”‚                                                                             
â”‚
â”‚ auto_find_batch_size                    â”‚ No                                                                          
â”‚
â”‚ full_determinism                        â”‚ No                                                                          
â”‚
â”‚ torchdynamo                             â”‚ None                                                                        
â”‚
â”‚ ray_scope                               â”‚ last                                                                        
â”‚
â”‚ ddp_timeout                             â”‚ 1800                                                                        
â”‚
â”‚ torch_compile                           â”‚ No                                                                          
â”‚
â”‚ torch_compile_backend                   â”‚ None                                                                        
â”‚
â”‚ torch_compile_mode                      â”‚ None                                                                        
â”‚
â”‚ include_tokens_per_second               â”‚ No                                                                          
â”‚
â”‚ include_num_input_tokens_seen           â”‚ no                                                                          
â”‚
â”‚ neftune_noise_alpha                     â”‚ None                                                                        
â”‚
â”‚ optim_target_modules                    â”‚ None                                                                        
â”‚
â”‚ batch_eval_metrics                      â”‚ No                                                                          
â”‚
â”‚ eval_on_start                           â”‚ No                                                                          
â”‚
â”‚ use_liger_kernel                        â”‚ No                                                                          
â”‚
â”‚ liger_kernel_config                     â”‚ None                                                                        
â”‚
â”‚ eval_use_gather_object                  â”‚ No                                                                          
â”‚
â”‚ average_tokens_across_devices           â”‚ Yes                                                                         
â”‚
â”‚ model_init_kwargs                       â”‚ None                                                                        
â”‚
â”‚ disable_dropout                         â”‚ No                                                                          
â”‚
â”‚ cast_lm_head_to_fp32                    â”‚ No                                                                          
â”‚
â”‚ num_generations                         â”‚ 2                                                                           
â”‚
â”‚ num_generations_eval                    â”‚ None                                                                        
â”‚
â”‚ max_completion_length                   â”‚ 32                                                                          
â”‚
â”‚ ds3_gather_for_generation               â”‚ Yes                                                                         
â”‚
â”‚ shuffle_dataset                         â”‚ Yes                                                                         
â”‚
â”‚ generation_batch_size                   â”‚ 2                                                                           
â”‚
â”‚ steps_per_generation                    â”‚ 1                                                                           
â”‚
â”‚ temperature                             â”‚ 1.0                                                                         
â”‚
â”‚ top_p                                   â”‚ 1.0                                                                         
â”‚
â”‚ top_k                                   â”‚ None                                                                        
â”‚
â”‚ min_p                                   â”‚ None                                                                        
â”‚
â”‚ generation_kwargs                       â”‚ None                                                                        
â”‚
â”‚ chat_template_kwargs                    â”‚ None                                                                        
â”‚
â”‚ repetition_penalty                      â”‚ 1.0                                                                         
â”‚
â”‚ use_transformers_paged                  â”‚ No                                                                          
â”‚
â”‚ cache_implementation                    â”‚ None                                                                        
â”‚
â”‚ use_vllm                                â”‚ No                                                                          
â”‚
â”‚ vllm_mode                               â”‚ server                                                                      
â”‚
â”‚ vllm_model_impl                         â”‚ vllm                                                                        
â”‚
â”‚ vllm_enable_sleep_mode                  â”‚ No                                                                          
â”‚
â”‚ vllm_guided_decoding_regex              â”‚ None                                                                        
â”‚
â”‚ vllm_server_base_url                    â”‚ None                                                                        
â”‚
â”‚ vllm_server_host                        â”‚ 0.0.0.0                                                                     
â”‚
â”‚ vllm_server_port                        â”‚ 8000                                                                        
â”‚
â”‚ vllm_server_timeout                     â”‚ 240.0                                                                       
â”‚
â”‚ vllm_gpu_memory_utilization             â”‚ 0.3                                                                         
â”‚
â”‚ vllm_max_model_length                   â”‚ None                                                                        
â”‚
â”‚ vllm_tensor_parallel_size               â”‚ 1                                                                           
â”‚
â”‚ beta                                    â”‚ 0.0                                                                         
â”‚
â”‚ num_iterations                          â”‚ 1                                                                           
â”‚
â”‚ epsilon                                 â”‚ 0.2                                                                         
â”‚
â”‚ delta                                   â”‚ None                                                                        
â”‚
â”‚ epsilon_high                            â”‚ None                                                                        
â”‚
â”‚ sapo_temperature_neg                    â”‚ 1.05                                                                        
â”‚
â”‚ sapo_temperature_pos                    â”‚ 1.0                                                                         
â”‚
â”‚ importance_sampling_level               â”‚ token                                                                       
â”‚
â”‚ reward_weights                          â”‚ None                                                                        
â”‚
â”‚ scale_rewards                           â”‚ group                                                                       
â”‚
â”‚ loss_type                               â”‚ dapo                                                                        
â”‚
â”‚ mask_truncated_completions              â”‚ No                                                                          
â”‚
â”‚ sync_ref_model                          â”‚ No                                                                          
â”‚
â”‚ ref_model_mixup_alpha                   â”‚ 0.6                                                                         
â”‚
â”‚ ref_model_sync_steps                    â”‚ 512                                                                         
â”‚
â”‚ top_entropy_quantile                    â”‚ 1.0                                                                         
â”‚
â”‚ use_liger_loss                          â”‚ None                                                                        
â”‚
â”‚ vllm_importance_sampling_correction     â”‚ Yes                                                                         
â”‚
â”‚ vllm_importance_sampling_mode           â”‚ sequence_mask                                                               
â”‚
â”‚ vllm_importance_sampling_cap            â”‚ 3.0                                                                         
â”‚
â”‚ use_bias_correction_kl                  â”‚ No                                                                          
â”‚
â”‚ log_completions                         â”‚ No                                                                          
â”‚
â”‚ num_completions_to_print                â”‚ None                                                                        
â”‚
â”‚ log_unique_prompts                      â”‚ No                                                                          
â”‚
â”‚ max_prompt_length                       â”‚ None                                                                        
â”‚
â”‚ wandb_log_unique_prompts                â”‚ None                                                                        
â”‚
â”‚ distributed_state                       â”‚ Distributed environment: DistributedType.NO                                 
â”‚
â”‚                                         â”‚ Num processes: 1                                                            
â”‚
â”‚                                         â”‚ Process index: 0                                                            
â”‚
â”‚                                         â”‚ Local process index: 0                                                      
â”‚
â”‚                                         â”‚ Device: cuda                                                                
â”‚
â”‚                                         â”‚                                                                             
â”‚
â”‚ deepspeed_plugin                        â”‚ None                                                                        
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


  0%|          | 0/10 [00:00<?, ?it/s]Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": [
    2
  ],
  "pad_token_id": 2
}


 10%|â–ˆ         | 1/10 [00:03<00:33,  3.72s/it]    Step 1: loss: 0.0000 | lr: 1.00e-06 | grad: 0.00 | epoch: 0.10 | GPU: 
1.5/8.0GB
  Step 1/10 (10.0%) loss=0.0000 | lr=1.00e-06 | grad=0.000
  GPU 0: 1.55GB allocated / 2.22GB reserved / 8.0GB total



 10%|â–ˆ         | 1/10 [00:03<00:33,  3.72s/it]Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": [
    2
  ],
  "pad_token_id": 2
}


 20%|â–ˆâ–ˆ        | 2/10 [00:06<00:24,  3.06s/it]{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 
210.0, 'completions/mean_length': 32.0, 'completions/min_length': 32.0, 'completions/max_length': 32.0, 
'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 
'completions/max_terminated_length': 0.0, 'rewards/reward_func/mean': 0.009999999776482582, 'rewards/reward_func/std': 
0.0, 'reward': 0.009999999776482582, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 0.8662897348403931, 
'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 
'clip_ratio/region_mean': 0.0, 'step_time': 3.658582142999876, 'epoch': 0.1}
    Step 2: loss: 0.0000 | lr: 9.00e-07 | grad: 0.00 | epoch: 0.20 | GPU: 1.5/8.0GB
  Step 2/10 (20.0%) loss=0.0000 | lr=9.00e-07 | grad=0.000
  GPU 0: 1.55GB allocated / 2.67GB reserved / 8.0GB total



 20%|â–ˆâ–ˆ        | 2/10 [00:06<00:24,  3.06s/it]Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": [
    2
  ],
  "pad_token_id": 2
}


 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:08<00:19,  2.73s/it]{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9e-07, 'num_tokens': 
568.0, 'completions/mean_length': 32.0, 'completions/min_length': 32.0, 'completions/max_length': 32.0, 
'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 
'completions/max_terminated_length': 0.0, 'rewards/reward_func/mean': 0.009999999776482582, 'rewards/reward_func/std': 
0.0, 'reward': 0.009999999776482582, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 0.8037395477294922, 
'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 
'clip_ratio/region_mean': 0.0, 'step_time': 2.5564575680000416, 'epoch': 0.2}
    Step 3: loss: 0.0000 | lr: 8.00e-07 | grad: 0.00 | epoch: 0.30 | GPU: 1.5/8.0GB
  Step 3/10 (30.0%) loss=0.0000 | lr=8.00e-07 | grad=0.000
  GPU 0: 1.55GB allocated / 2.67GB reserved / 8.0GB total



 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:08<00:19,  2.73s/it]Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": [
    2
  ],
  "pad_token_id": 2
}


 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:11<00:16,  2.83s/it]{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8e-07, 'num_tokens': 
830.0, 'completions/mean_length': 32.0, 'completions/min_length': 32.0, 'completions/max_length': 32.0, 
'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 
'completions/max_terminated_length': 0.0, 'rewards/reward_func/mean': 0.009999999776482582, 'rewards/reward_func/std': 
0.0, 'reward': 0.009999999776482582, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 0.7315382361412048, 
'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 
'clip_ratio/region_mean': 0.0, 'step_time': 2.286592462000044, 'epoch': 0.3}
    Step 4: loss: 0.0000 | lr: 7.00e-07 | grad: 0.00 | epoch: 0.40 | GPU: 1.5/8.0GB
  Step 4/10 (40.0%) loss=0.0000 | lr=7.00e-07 | grad=0.000
  GPU 0: 1.55GB allocated / 2.67GB reserved / 8.0GB total



 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:11<00:16,  2.83s/it]Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": [
    2
  ],
  "pad_token_id": 2
}


 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:14<00:13,  2.70s/it]{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7e-07, 'num_tokens': 
1042.0, 'completions/mean_length': 32.0, 'completions/min_length': 32.0, 'completions/max_length': 32.0, 
'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 
'completions/max_terminated_length': 0.0, 'rewards/reward_func/mean': 0.009999999776482582, 'rewards/reward_func/std': 
0.0, 'reward': 0.009999999776482582, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 1.006459355354309, 
'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 
'clip_ratio/region_mean': 0.0, 'step_time': 2.9346252539999114, 'epoch': 0.4}
    Step 5: loss: 0.0000 | lr: 6.00e-07 | grad: 0.00 | epoch: 0.50 | GPU: 1.5/8.0GB
  Step 5/10 (50.0%) loss=0.0000 | lr=6.00e-07 | grad=0.000
  GPU 0: 1.55GB allocated / 3.75GB reserved / 8.0GB total



 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:14<00:13,  2.70s/it]Saving model checkpoint to 
runs/20260111_064045_89cu/test-model-grpo/checkpoint-5
Configuration saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-5/config.json
Configuration saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-5/generation_config.json
Model weights saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-5/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-5/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-5/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-5/special_tokens_map.json
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6e-07, 'num_tokens': 1894.0, 'completions/mean_length': 32.0, 
'completions/min_length': 32.0, 'completions/max_length': 32.0, 'completions/clipped_ratio': 1.0, 
'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 
'completions/max_terminated_length': 0.0, 'rewards/reward_func/mean': 0.009999999776482582, 'rewards/reward_func/std': 
0.0, 'reward': 0.009999999776482582, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 1.2727196216583252, 
'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 
'clip_ratio/region_mean': 0.0, 'step_time': 2.4171883479993994, 'epoch': 0.5}
    âœ“ Checkpoint saved at step 5
  âœ“ Checkpoint saved at step 5 â†’ runs/20260111_064045_89cu/test-model-grpo
Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": [
    2
  ],
  "pad_token_id": 2
}


 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:23<00:19,  4.85s/it]    Step 6: loss: 0.0000 | lr: 5.00e-07 | grad: 0.00 | epoch: 0.60 | GPU: 
1.5/8.0GB
  Step 6/10 (60.0%) loss=0.0000 | lr=5.00e-07 | grad=0.000
  GPU 0: 1.55GB allocated / 3.75GB reserved / 8.0GB total



 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:23<00:19,  4.85s/it]Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": [
    2
  ],
  "pad_token_id": 2
}


 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:25<00:12,  4.06s/it]{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-07, 'num_tokens': 
2120.0, 'completions/mean_length': 32.0, 'completions/min_length': 32.0, 'completions/max_length': 32.0, 
'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 
'completions/max_terminated_length': 0.0, 'rewards/reward_func/mean': 0.009999999776482582, 'rewards/reward_func/std': 
0.0, 'reward': 0.009999999776482582, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 1.937563180923462, 
'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 
'clip_ratio/region_mean': 0.0, 'step_time': 2.391046582999479, 'epoch': 0.6}
    Step 7: loss: 0.0000 | lr: 4.00e-07 | grad: 0.00 | epoch: 0.70 | GPU: 1.5/8.0GB
  Step 7/10 (70.0%) loss=0.0000 | lr=4.00e-07 | grad=0.000
  GPU 0: 1.55GB allocated / 3.75GB reserved / 8.0GB total



 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:25<00:12,  4.06s/it]Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": [
    2
  ],
  "pad_token_id": 2
}


 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:28<00:07,  3.63s/it]{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4e-07, 'num_tokens': 
2400.0, 'completions/mean_length': 32.0, 'completions/min_length': 32.0, 'completions/max_length': 32.0, 
'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 
'completions/max_terminated_length': 0.0, 'rewards/reward_func/mean': 0.009999999776482582, 'rewards/reward_func/std': 
0.0, 'reward': 0.009999999776482582, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 0.7882146835327148, 
'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 
'clip_ratio/region_mean': 0.0, 'step_time': 2.4059908099989116, 'epoch': 0.7}
    Step 8: loss: 0.0000 | lr: 3.00e-07 | grad: 0.00 | epoch: 0.80 | GPU: 1.5/8.0GB
  Step 8/10 (80.0%) loss=0.0000 | lr=3.00e-07 | grad=0.000
  GPU 0: 1.55GB allocated / 3.75GB reserved / 8.0GB total



 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:28<00:07,  3.63s/it]Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": [
    2
  ],
  "pad_token_id": 2
}


 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:31<00:03,  3.53s/it]{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3e-07, 'num_tokens': 
2658.0, 'completions/mean_length': 32.0, 'completions/min_length': 32.0, 'completions/max_length': 32.0, 
'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 
'completions/max_terminated_length': 0.0, 'rewards/reward_func/mean': 0.009999999776482582, 'rewards/reward_func/std': 
0.0, 'reward': 0.009999999776482582, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 1.0324459075927734, 
'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 
'clip_ratio/region_mean': 0.0, 'step_time': 2.645071431999895, 'epoch': 0.8}
    Step 9: loss: 0.0000 | lr: 2.00e-07 | grad: 0.00 | epoch: 0.90 | GPU: 1.5/8.0GB
  Step 9/10 (90.0%) loss=0.0000 | lr=2.00e-07 | grad=0.000
  GPU 0: 1.55GB allocated / 3.75GB reserved / 8.0GB total



 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:31<00:03,  3.53s/it]Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": [
    2
  ],
  "pad_token_id": 2
}

{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-07, 'num_tokens': 2910.0, 'completions/mean_length': 32.0, 
'completions/min_length': 32.0, 'completions/max_length': 32.0, 'completions/clipped_ratio': 1.0, 
'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 
'completions/max_terminated_length': 0.0, 'rewards/reward_func/mean': 0.009999999776482582, 'rewards/reward_func/std': 
0.0, 'reward': 0.009999999776482582, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 0.5873597264289856, 
'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 
'clip_ratio/region_mean': 0.0, 'step_time': 2.5367942439988838, 'epoch': 0.9}
  Step 10 | 2.664s/step | avg: 2.739s | ETA: 0.0s

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:34<00:00,  3.27s/it]    Step 10: loss: 0.0000 | lr: 1.00e-07 | grad: 0.00 | epoch: 1.00 | 
GPU: 1.5/8.0GB
  Step 10/10 (100.0%) loss=0.0000 | lr=1.00e-07 | grad=0.000
  GPU 0: 1.55GB allocated / 3.75GB reserved / 8.0GB total



100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:34<00:00,  3.27s/it]Saving model checkpoint to 
runs/20260111_064045_89cu/test-model-grpo/checkpoint-10
Configuration saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-10/config.json
Configuration saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-10/generation_config.json
Model weights saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-10/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-10/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-10/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-grpo/checkpoint-10/special_tokens_map.json
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-07, 'num_tokens': 3122.0, 'completions/mean_length': 32.0, 
'completions/min_length': 32.0, 'completions/max_length': 32.0, 'completions/clipped_ratio': 1.0, 
'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 
'completions/max_terminated_length': 0.0, 'rewards/reward_func/mean': 0.009999999776482582, 'rewards/reward_func/std': 
0.0, 'reward': 0.009999999776482582, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 0.8853991627693176, 
'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 
'clip_ratio/region_mean': 0.0, 'step_time': 2.6529684719989746, 'epoch': 1.0}
    âœ“ Checkpoint saved at step 10
  âœ“ Checkpoint saved at step 10 â†’ runs/20260111_064045_89cu/test-model-grpo


Training completed. Do not forget to share your model on huggingface.co/models =)


    Step 10: loss: 0.0000 | epoch: 1.00 | GPU: 1.5/8.0GB
  Step 10/10 (100.0%)
  GPU 0: 1.55GB allocated / 3.75GB reserved / 8.0GB total



100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:38<00:00,  3.27s/it]{'train_runtime': 39.0025, 'train_samples_per_second': 0.513, 
'train_steps_per_second': 0.256, 'train_loss': 0.0, 'epoch': 1.0}
  GRPO â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 10/10 | 0:00:33 < 0:00:00


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GRPO Training Complete 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Total Steps:   10
 Total Epochs:  1.00
 Duration:      39.0s
 Steps/sec:     0.26
 Final Loss:    0.0000


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ GRPO Training Complete!                                                                                               
â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Total steps: 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
  Average step time: 2.739s
  Total steps: 10
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Training   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00                                                      
â”‚
â”‚ â ‹ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Step 10 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚
â”‚   â”‚ 
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚ â”‚
â”‚   â”‚ â”‚  Metric                     Value                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_runtime             39.002                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_samples_per_second   0.513                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_steps_per_second     0.256                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  total_flos                 0.000                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  train_loss                 0.000                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ â”‚  epoch                      1.000                                                                               
â”‚ â”‚ â”‚
â”‚   â”‚ 
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚ â”‚
â”‚   
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:38<00:00,  3.88s/it]

Saving GRPO model to: runs/20260111_064045_89cu/test-model-grpo
Saving model checkpoint to runs/20260111_064045_89cu/test-model-grpo
Configuration saved in runs/20260111_064045_89cu/test-model-grpo/config.json
Configuration saved in runs/20260111_064045_89cu/test-model-grpo/generation_config.json
Model weights saved in runs/20260111_064045_89cu/test-model-grpo/model.safetensors
chat template saved in runs/20260111_064045_89cu/test-model-grpo/chat_template.jinja
tokenizer config file saved in runs/20260111_064045_89cu/test-model-grpo/tokenizer_config.json
Special tokens file saved in runs/20260111_064045_89cu/test-model-grpo/special_tokens_map.json

âœ“ GRPO model saved to runs/20260111_064045_89cu/test-model-grpo
âœ“ GRPO completed in 46.6s
  âœ“ GRPO Training
     Completed
â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ Metric   â”ƒ Value â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ Duration â”‚ 46.6s â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜

  Running GRPO... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 4/4 0:03:13 0:00:00

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Pipeline Results 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


         Pipeline Results
â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Algorithm â”ƒ  Status  â”ƒ Duration â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”©
â”‚ SFT       â”‚  PASSED  â”‚    35.2s â”‚
â”‚ REWARD    â”‚  PASSED  â”‚    22.7s â”‚
â”‚ DPO       â”‚  PASSED  â”‚ 1m 33.5s â”‚
â”‚ GRPO      â”‚  PASSED  â”‚    46.6s â”‚
â”‚           â”‚          â”‚          â”‚
â”‚ TOTAL     â”‚ 4 passed â”‚ 3m 18.0s â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


âœ“ All 4 algorithm(s) completed successfully!
Total pipeline time: 3m 18.0s

[1;34mwandb[0m:
[1;34mwandb[0m: ğŸš€ View run [33mcelestial-mountain-3[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260111_064052-zap0zm1t/logs[0m

âœ“ smollm2_135m.py completed in 3m 36.1s

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Running qwen2.5_0.5b.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Command: python /home/burny/projects/ml-playground/llmrl/qwen2.5_0.5b.py
Working directory: /home/burny/projects/ml-playground/llmrl


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                       
â”‚
â”‚  Training Pipeline                                                                                                    
â”‚
â”‚  Run ID: 20260111_064423_khr8 | Running 4 algorithm(s): sft, reward, dpo, grpo                                        
â”‚
â”‚                                                                                                                       
â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ System Information 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

                                 System Information
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Component         â”ƒ Details                                                      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Platform          â”‚ Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.39 â”‚
â”‚ Python            â”‚ 3.12.3                                                       â”‚
â”‚ Working Directory â”‚ /home/burny/projects/ml-playground/llmrl                     â”‚
â”‚ Timestamp         â”‚ 2026-01-11 06:44:23                                          â”‚
â”‚ GPU 0             â”‚ NVIDIA GeForce RTX 5070 Laptop GPU (8.0 GB)                  â”‚
â”‚ CUDA Version      â”‚ 12.8                                                         â”‚
â”‚ RAM               â”‚ 15.3 GB (66.3% used)                                         â”‚
â”‚ Disk              â”‚ 1006.9 GB (8.9% used)                                        â”‚
â”‚ CPU Cores         â”‚ 16                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Pipeline Configuration 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SFT
                                 SFT Config
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                   â”ƒ Value                                      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ model_name                  â”‚ Qwen/Qwen2.5-0.5B                          â”‚
â”‚ output_dir                  â”‚ runs/20260111_064423_khr8/Qwen2.5-0.5B-SFT â”‚
â”‚ dataset_name                â”‚ trl-lib/Capybara                           â”‚
â”‚ dataset_split               â”‚ train                                      â”‚
â”‚ max_samples                 â”‚ None                                       â”‚
â”‚ per_device_train_batch_size â”‚ 8                                          â”‚
â”‚ gradient_accumulation_steps â”‚ 4                                          â”‚
â”‚ max_steps                   â”‚ -1                                         â”‚
â”‚ gradient_checkpointing      â”‚ Yes                                        â”‚
â”‚ bf16                        â”‚ Yes                                        â”‚
â”‚ use_liger_kernel            â”‚ Yes                                        â”‚
â”‚ dataloader_pin_memory       â”‚ Yes                                        â”‚
â”‚ dataloader_num_workers      â”‚ 4                                          â”‚
â”‚ logging_steps               â”‚ 1                                          â”‚
â”‚ logging_strategy            â”‚ steps                                      â”‚
â”‚ log_level                   â”‚ info                                       â”‚
â”‚ report_to                   â”‚ wandb                                      â”‚
â”‚ save_steps                  â”‚ 42                                         â”‚
â”‚ save_strategy               â”‚ steps                                      â”‚
â”‚ save_total_limit            â”‚ 12                                         â”‚
â”‚ clean_output_dir            â”‚ No                                         â”‚
â”‚ verbose                     â”‚ Yes                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

REWARD
                                 REWARD Config
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                   â”ƒ Value                                         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ model_name                  â”‚ Qwen/Qwen2.5-0.5B-Instruct                    â”‚
â”‚ output_dir                  â”‚ runs/20260111_064423_khr8/Qwen2.5-0.5B-Reward â”‚
â”‚ dataset_name                â”‚ trl-lib/ultrafeedback_binarized               â”‚
â”‚ dataset_split               â”‚ train                                         â”‚
â”‚ max_samples                 â”‚ None                                          â”‚
â”‚ per_device_train_batch_size â”‚ 8                                             â”‚
â”‚ gradient_accumulation_steps â”‚ 4                                             â”‚
â”‚ max_steps                   â”‚ -1                                            â”‚
â”‚ gradient_checkpointing      â”‚ Yes                                           â”‚
â”‚ bf16                        â”‚ Yes                                           â”‚
â”‚ use_liger_kernel            â”‚ Yes                                           â”‚
â”‚ dataloader_pin_memory       â”‚ Yes                                           â”‚
â”‚ dataloader_num_workers      â”‚ 4                                             â”‚
â”‚ logging_steps               â”‚ 1                                             â”‚
â”‚ logging_strategy            â”‚ steps                                         â”‚
â”‚ log_level                   â”‚ info                                          â”‚
â”‚ report_to                   â”‚ wandb                                         â”‚
â”‚ save_steps                  â”‚ 156                                           â”‚
â”‚ save_strategy               â”‚ steps                                         â”‚
â”‚ save_total_limit            â”‚ 12                                            â”‚
â”‚ clean_output_dir            â”‚ No                                            â”‚
â”‚ verbose                     â”‚ Yes                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DPO
                                 DPO Config
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                   â”ƒ Value                                      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ model_name                  â”‚ Qwen/Qwen2.5-0.5B-Instruct                 â”‚
â”‚ output_dir                  â”‚ runs/20260111_064423_khr8/Qwen2.5-0.5B-DPO â”‚
â”‚ dataset_name                â”‚ trl-lib/ultrafeedback_binarized            â”‚
â”‚ dataset_split               â”‚ train                                      â”‚
â”‚ max_samples                 â”‚ None                                       â”‚
â”‚ per_device_train_batch_size â”‚ 2                                          â”‚
â”‚ gradient_accumulation_steps â”‚ 4                                          â”‚
â”‚ max_steps                   â”‚ -1                                         â”‚
â”‚ gradient_checkpointing      â”‚ Yes                                        â”‚
â”‚ bf16                        â”‚ Yes                                        â”‚
â”‚ use_liger_kernel            â”‚ Yes                                        â”‚
â”‚ dataloader_pin_memory       â”‚ Yes                                        â”‚
â”‚ dataloader_num_workers      â”‚ 4                                          â”‚
â”‚ logging_steps               â”‚ 1                                          â”‚
â”‚ logging_strategy            â”‚ steps                                      â”‚
â”‚ log_level                   â”‚ info                                       â”‚
â”‚ report_to                   â”‚ wandb                                      â”‚
â”‚ save_steps                  â”‚ 625                                        â”‚
â”‚ save_strategy               â”‚ steps                                      â”‚
â”‚ save_total_limit            â”‚ 12                                         â”‚
â”‚ clean_output_dir            â”‚ No                                         â”‚
â”‚ verbose                     â”‚ Yes                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

GRPO
                                 GRPO Config
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter                   â”ƒ Value                                       â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ model_name                  â”‚ Qwen/Qwen2.5-0.5B-Instruct                  â”‚
â”‚ output_dir                  â”‚ runs/20260111_064423_khr8/Qwen2.5-0.5B-GRPO â”‚
â”‚ dataset_name                â”‚ trl-lib/DeepMath-103K                       â”‚
â”‚ dataset_split               â”‚ train                                       â”‚
â”‚ max_samples                 â”‚ None                                        â”‚
â”‚ per_device_train_batch_size â”‚ 2                                           â”‚
â”‚ gradient_accumulation_steps â”‚ 4                                           â”‚
â”‚ max_steps                   â”‚ -1                                          â”‚
â”‚ gradient_checkpointing      â”‚ Yes                                         â”‚
â”‚ bf16                        â”‚ Yes                                         â”‚
â”‚ use_liger_kernel            â”‚ Yes                                         â”‚
â”‚ dataloader_pin_memory       â”‚ Yes                                         â”‚
â”‚ dataloader_num_workers      â”‚ 4                                           â”‚
â”‚ logging_steps               â”‚ 1                                           â”‚
â”‚ logging_strategy            â”‚ steps                                       â”‚
â”‚ log_level                   â”‚ info                                        â”‚
â”‚ report_to                   â”‚ wandb                                       â”‚
â”‚ save_steps                  â”‚ 1073                                        â”‚
â”‚ save_strategy               â”‚ steps                                       â”‚
â”‚ save_total_limit            â”‚ 12                                          â”‚
â”‚ clean_output_dir            â”‚ No                                          â”‚
â”‚ verbose                     â”‚ Yes                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Training Progress 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€



â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SFT Training 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â„¹ Model: Qwen/Qwen2.5-0.5B
â„¹ Dataset: trl-lib/Capybara
â„¹ Output: runs/20260111_064423_khr8/Qwen2.5-0.5B-SFT
â„¹ Output directory ready: runs/20260111_064423_khr8/Qwen2.5-0.5B-SFT
[06:44:23] INFO     Starting SFT training with model=Qwen/Qwen2.5-0.5B                                                  
sft.py:40
Loading dataset: trl-lib/Capybara (split: train)

             Dataset Information
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Property    â”ƒ Value                       â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Dataset     â”‚ trl-lib/Capybara            â”‚
â”‚ Samples     â”‚ 15,806                      â”‚
â”‚ Columns     â”‚ source, messages, num_turns â”‚
â”‚ Sample Keys â”‚ source, messages, num_turns â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â„¹ Creating SFT trainer...
